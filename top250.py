import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pymysql
import warnings
from math import pi

# å¯¼å…¥è¯äº‘å’Œä¸­æ–‡åˆ†è¯åº“
import jieba
from wordcloud import WordCloud, STOPWORDS
from collections import Counter

# å› ä¸ºä¸å†è¿›è¡Œç¥¨æˆ¿é¢„æµ‹ï¼Œç›¸å…³çš„æœºå™¨å­¦ä¹ åº“å¯ä»¥ä¸å¯¼å…¥æˆ–æ³¨é‡Šæ‰
# from sklearn.model_selection import train_test_split
# from sklearn.ensemble import RandomForestRegressor
# from sklearn.linear_model import LinearRegression
# from sklearn.metrics import mean_squared_error, r2_score
# from sklearn.preprocessing import StandardScaler


# --- Streamlit é¡µé¢é…ç½® (å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤) ---
st.set_page_config(layout="wide", page_title="è±†ç“£ç”µå½±åˆ†æ - Top 250")

# è®¾ç½® Matplotlib å­—ä½“ä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']  # æˆ–è€… 'Microsoft YaHei'ï¼Œæ ¹æ®æ‚¨çš„ç³»ç»Ÿå­—ä½“é€‰æ‹©
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜


# --- æ•°æ®åº“è¿æ¥ (ä½¿ç”¨ Streamlit ç¼“å­˜èµ„æºï¼Œé¿å…æ¯æ¬¡è¿è¡Œéƒ½é‡æ–°è¿æ¥) ---
@st.cache_resource
def get_database_connection_resource():
    """è·å–å¹¶ç¼“å­˜æ•°æ®åº“è¿æ¥"""
    try:
        # è¯·æ ¹æ®æ‚¨çš„å®é™…MySQLé…ç½®ä¿®æ”¹è¿™äº›å‚æ•°
        db = pymysql.connect(host='localhost',
                             user='root',
                             password='',  # <-- è¯·åœ¨è¿™é‡Œå¡«å…¥æ‚¨çš„MySQLå¯†ç 
                             database='douban',  # æ•°æ®åº“ååº”ä¸º 'douban'
                             charset='utf8mb4')
        st.success("æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
        return db
    except pymysql.err.OperationalError as e:
        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥ (è¯·æ£€æŸ¥MySQLæœåŠ¡æˆ–è¿æ¥å‚æ•°): {e}")
        st.stop()  # åœæ­¢åº”ç”¨è¿è¡Œï¼Œç›´åˆ°é—®é¢˜è§£å†³
    except Exception as e:
        st.error(f"å‘ç”ŸæœªçŸ¥æ•°æ®åº“é”™è¯¯: {e}")
        st.stop()


db_connection = get_database_connection_resource()


# --- æ•°æ®åŠ è½½ä¸é¢„å¤„ç† (ä½¿ç”¨ Streamlit ç¼“å­˜æ•°æ®) ---
@st.cache_data(ttl=3600)  # æ•°æ®ç¼“å­˜1å°æ—¶
def load_and_preprocess_data(_db_conn) -> pd.DataFrame:
    """ä»æ•°æ®åº“åŠ è½½æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹"""
    st.info("æ­£åœ¨åŠ è½½å’Œé¢„å¤„ç†è±†ç“£ç”µå½±æ•°æ®...")

    try:
        # ä» 'movie' è¡¨åŠ è½½æ•°æ®
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            df = pd.read_sql(f'SELECT * FROM `movie`', _db_conn)
        st.success(f"æˆåŠŸä» 'movie' è¡¨åŠ è½½ {len(df)} è¡Œæ•°æ®ã€‚")
        if df.empty:
            st.warning("`movie` è¡¨ä¸­æ²¡æœ‰æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“æˆ–çˆ¬è™«æ˜¯å¦å·²è¿è¡Œã€‚")
            return pd.DataFrame()  # è¿”å›ç©ºDataFrame
    except Exception as e:
        st.error(f"ä»è¡¨ 'movie' åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

    df = df.copy()  # åˆ›å»ºå‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning

    # --- 1. åˆ—åæ˜ å°„ ---
    # å°†æ•°æ®åº“åˆ—åæ˜ å°„åˆ°ä»£ç ä¸­ä½¿ç”¨çš„æ›´é€šç”¨æˆ–æ›´å…·æè¿°æ€§çš„åˆ—å
    column_mapping = {
        'ä¸­æ–‡å': 'ç”µå½±å',
        'è¯„åˆ†': 'è±†ç“£è¯„åˆ†',
        'è¯„ä»·äººæ•°': 'è±†ç“£è¯„è®ºæ•°',
        'ä¸»æ¼”': 'æ¼”å‘˜',  # ä¿æŒä¸€è‡´ï¼Œæ–¹ä¾¿åç»­å¤„ç†
        'ç”µå½±è¯­å½•': 'ç”µå½±è¯­å½•',  # æ–°å¢åˆ—
        'ä¸Šæ˜ å¹´ä»½': 'ä¸Šæ˜ å¹´ä»½_str',  # ä¸´æ—¶å˜é‡ï¼Œç”¨äºåç»­è½¬æ¢
        'æ—¶é•¿': 'æ—¶é•¿_str'  # ä¸´æ—¶å˜é‡ï¼Œç”¨äºåç»­è½¬æ¢
    }
    df.rename(columns=column_mapping, inplace=True)

    # --- 2. ä¸Šæ˜ å¹´ä»½å¤„ç† (ä» varchar æå–å››ä½æ•°å­—å¹´ä»½) ---
    if 'ä¸Šæ˜ å¹´ä»½_str' in df.columns:
        # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–å››ä½æ•°å­—ä½œä¸ºå¹´ä»½
        df['ä¸Šæ˜ å¹´ä»½'] = df['ä¸Šæ˜ å¹´ä»½_str'].astype(str).str.extract(r'(\d{4})', expand=False)
        df['ä¸Šæ˜ å¹´ä»½'] = pd.to_numeric(df['ä¸Šæ˜ å¹´ä»½'], errors='coerce').fillna(-1).astype(int)
        df.drop(columns=['ä¸Šæ˜ å¹´ä»½_str'], inplace=True)
    else:
        df['ä¸Šæ˜ å¹´ä»½'] = -1
        st.warning("è­¦å‘Š: æ•°æ®åº“ä¸­ç¼ºå°‘åˆ— 'ä¸Šæ˜ å¹´ä»½'ã€‚å·²å¡«å……é»˜è®¤å€¼-1ã€‚")

    # --- 3. æ—¶é•¿å¤„ç† (ä» varchar æå–åˆ†é’Ÿæ•°) ---
    if 'æ—¶é•¿_str' in df.columns:
        # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—ï¼Œä¾‹å¦‚ "120åˆ†é’Ÿ" -> 120
        df['æ—¶é•¿'] = df['æ—¶é•¿_str'].astype(str).str.extract(r'(\d+)', expand=False)
        df['æ—¶é•¿'] = pd.to_numeric(df['æ—¶é•¿'], errors='coerce').fillna(0).astype(int)
        df.drop(columns=['æ—¶é•¿_str'], inplace=True)
    else:
        df['æ—¶é•¿'] = 0
        st.warning("è­¦å‘Š: æ•°æ®åº“ä¸­ç¼ºå°‘åˆ— 'æ—¶é•¿'ã€‚å·²å¡«å……é»˜è®¤å€¼0ã€‚")

    # --- 4. å¤„ç†å¤šå€¼åˆ†ç±»ç‰¹å¾ ('å¯¼æ¼”', 'æ¼”å‘˜', 'ç±»å‹', 'åœ°åŒº', 'è¯­è¨€') ---
    # åˆ›å»º '_list' ç»“å°¾çš„æ–°åˆ—æ¥å­˜å‚¨åˆ—è¡¨å½¢å¼çš„æ•°æ®ï¼Œè¿™äº›åˆ—ä¼šä¿ç•™ç”¨äºEDA
    original_multi_value_cols = ['å¯¼æ¼”', 'æ¼”å‘˜', 'ç±»å‹', 'åœ°åŒº', 'è¯­è¨€']
    for col in original_multi_value_cols:
        if col in df.columns:
            # ç¡®ä¿å¤„ç†éå­—ç¬¦ä¸²å€¼ï¼Œä¾‹å¦‚ NaN
            df[col + '_list'] = df[col].apply(
                lambda x: [item.strip() for item in str(x).split(',') if item.strip()] if pd.notnull(x) else []
            )
        else:
            df[col + '_list'] = [[]] * len(df)
            st.warning(f"è­¦å‘Š: æ•°æ®åº“ä¸­ç¼ºå°‘åˆ— '{col}'ã€‚å·²åˆ›å»ºç©ºåˆ—è¡¨åˆ—ã€‚")

    # --- 5. è½¬æ¢æ ¸å¿ƒæ•°å€¼ç‰¹å¾ä¸ºæ­£ç¡®çš„ç±»å‹å¹¶å¤„ç†ç¼ºå¤±å€¼ ---
    numeric_cols_to_convert = {
        'è±†ç“£è¯„åˆ†': float,
        'è±†ç“£è¯„è®ºæ•°': int,
        'æ—¶é•¿': int
    }

    for col, dtype in numeric_cols_to_convert.items():
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            df[col] = df[col].fillna(0.0 if dtype == float else 0)  # å¡«å……NaNå€¼
            try:
                df[col] = df[col].astype(dtype)
            except Exception as e:
                st.error(f"ä¸¥é‡é”™è¯¯: åˆ— '{col}' æ— æ³•è½¬æ¢ä¸º {dtype} ç±»å‹ã€‚è¯·æ£€æŸ¥æ•°æ®æºä¸­è¯¥åˆ—çš„å€¼ã€‚")
                df[col] = 0.0 if dtype == float else 0  # å°è¯•å®‰å…¨åœ°è®¾ä¸ºé»˜è®¤å€¼
        else:
            df[col] = 0.0 if dtype == float else 0
            st.warning(f"è­¦å‘Š: æ•°æ®åº“ä¸­ç¼ºå°‘åˆ— '{col}'ã€‚å·²åˆ›å»ºå¹¶å¡«å……é»˜è®¤å€¼ã€‚")

    # --- 6. è¿‡æ»¤ä¸é€‚åˆåˆ†æçš„ç”µå½± ---
    initial_rows = len(df)
    df = df[(df['è±†ç“£è¯„åˆ†'] > 0) & (df['è±†ç“£è¯„åˆ†'] <= 10)]  # è¯„åˆ†å¤§äº0ä¸”å°äºç­‰äº10
    df = df[df['è±†ç“£è¯„è®ºæ•°'] > 0]  # è¯„è®ºæ•°å¤§äº0
    df = df[df['æ—¶é•¿'] > 0]  # æ—¶é•¿å¤§äº0
    current_year = pd.Timestamp.now().year
    df = df[df['ä¸Šæ˜ å¹´ä»½'].isin(range(1900, current_year + 2))]  # é™åˆ¶å¹´ä»½èŒƒå›´ï¼Œå…è®¸æœªæ¥ä¸€å¹´

    st.write(
        f"å·²è¿‡æ»¤æ‰ {initial_rows - len(df)} è¡Œä¸é€‚åˆåˆ†æçš„ç”µå½±ï¼ˆä¾‹å¦‚ï¼šè¯„åˆ†0/è¯„è®ºæ•°0/æ—¶é•¿0/å¹´ä»½ä¸åˆç†ï¼‰ã€‚å‰©ä½™ {len(df)} è¡Œã€‚")

    if df.empty:
        st.warning("è¿‡æ»¤åæ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚è¯·æ£€æŸ¥æ•°æ®æºå’Œè¿‡æ»¤æ¡ä»¶ã€‚")
        return pd.DataFrame()

    # --- 7. æ¸…ç†åŸå§‹å­—ç¬¦ä¸²åˆ— (ä¿ç•™_listç‰ˆæœ¬ç”¨äºEDAï¼Œåˆ é™¤åŸå§‹å­—ç¬¦ä¸²åˆ—) ---
    # original_multi_value_cols å·²ç»ç”¨æ¥ç”Ÿæˆ_liståˆ—ï¼Œç°åœ¨å¯ä»¥åˆ é™¤åŸå§‹åˆ—
    cols_to_drop_original_string = [col for col in original_multi_value_cols if col in df.columns]
    # 'å¤–æ–‡å', 'ç”µå½±è¯­å½•', 'è¯¦æƒ…URL' è¿™äº›åŸå§‹åˆ—å¯èƒ½ä¹Ÿéœ€è¦ä¿ç•™ï¼Œå–å†³äºå®é™…éœ€æ±‚ã€‚è¿™é‡Œåªåˆ é™¤åŸå§‹çš„å¤šå€¼åˆ†ç±»ç‰¹å¾ã€‚
    df.drop(columns=cols_to_drop_original_string, inplace=True)

    # è±†ç“£æ•°æ®é€šå¸¸æ²¡æœ‰åœºå‡äººæ•°å’Œç¥¨æˆ¿ï¼Œç¡®ä¿è¿™äº›åˆ—ä¸å­˜åœ¨æˆ–ä¸º0
    if 'ç¥¨æˆ¿(ä¸‡å…ƒ)' not in df.columns:
        df['ç¥¨æˆ¿(ä¸‡å…ƒ)'] = 0.0
    if 'åœºå‡äººæ•°' not in df.columns:
        df['åœºå‡äººæ•°'] = 0.0

    st.success("æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹å®Œæˆã€‚")
    return df


# --- å¯¼æ¼”å½±å“åŠ›é›·è¾¾å›¾è¾…åŠ©å‡½æ•° ---
def plot_director_radar_chart(director_name, processed_df):
    """ç»˜åˆ¶å¯¼æ¼”å½±å“åŠ›é›·è¾¾å›¾"""
    director_movies = processed_df[processed_df['å¯¼æ¼”_list'].apply(lambda x: director_name in x)]

    if director_movies.empty:
        st.warning(f"æ•°æ®é›†ä¸­æœªæ‰¾åˆ°å¯¼æ¼” '{director_name}' çš„ç”µå½±ä¿¡æ¯ã€‚")
        return

    # è®¡ç®—å¯¼æ¼”ç›¸å…³æŒ‡æ ‡ (æ’é™¤ç¥¨æˆ¿å’Œåœºå‡äººæ•°ï¼Œèšç„¦è±†ç“£è¯„åˆ†ã€è¯„è®ºæ•°ã€æ—¶é•¿)
    total_movies = len(director_movies)
    avg_douban_score = director_movies['è±†ç“£è¯„åˆ†'].mean()
    avg_length = director_movies['æ—¶é•¿'].mean()
    avg_comments = director_movies['è±†ç“£è¯„è®ºæ•°'].mean()

    # è®¡ç®—æ•´ä½“å¹³å‡æŒ‡æ ‡ï¼Œç”¨äºæ ‡å‡†åŒ–
    overall_avg_douban_score = processed_df['è±†ç“£è¯„åˆ†'].mean()
    overall_avg_length = processed_df['æ—¶é•¿'].mean()
    overall_avg_comments = processed_df['è±†ç“£è¯„è®ºæ•°'].mean()

    all_directors_flat = [d for sublist in processed_df['å¯¼æ¼”_list'] for d in sublist]
    unique_directors_count = len(pd.Series(all_directors_flat).unique())
    overall_total_movies_per_director = len(processed_df) / unique_directors_count if unique_directors_count > 0 else 1

    categories = ['ç”µå½±æ•°é‡', 'å¹³å‡è¯„åˆ†', 'å¹³å‡ç‰‡é•¿', 'å¹³å‡è¯„è®ºæ•°']
    num_vars = len(categories)
    angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]  # è§’åº¦è®¡ç®—
    angles += angles[:1]  # é—­åˆé›·è¾¾å›¾

    # æ ‡å‡†åŒ–æŒ‡æ ‡å€¼ï¼Œé¿å…æŸä¸ªå€¼è¿‡å¤§æˆ–è¿‡å°å¯¼è‡´é›·è¾¾å›¾å¤±è¡¡
    epsilon = 1e-6  # é¿å…é™¤ä»¥é›¶
    values_director = [
        total_movies / (overall_total_movies_per_director + epsilon),
        avg_douban_score / (overall_avg_douban_score + epsilon),
        avg_length / (overall_avg_length + epsilon),
        avg_comments / (overall_avg_comments + epsilon)
    ]
    values_director = [min(v, 2.0) for v in values_director]  # å°†æ ‡å‡†åŒ–åçš„å€¼é™åˆ¶åœ¨ä¸€ä¸ªåˆç†èŒƒå›´å†…
    values_director += values_director[:1]

    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))
    ax.fill(angles, values_director, color='red', alpha=0.25)
    ax.plot(angles, values_director, color='red', linewidth=2, linestyle='solid', label=director_name)

    ax.set_yticklabels([])  # ä¸æ˜¾ç¤ºå¾„å‘åˆ»åº¦æ ‡ç­¾
    ax.set_xticks(angles[:-1])  # è®¾ç½®åˆ»åº¦ä½ç½®
    ax.set_xticklabels(categories, color='grey', size=12)  # è®¾ç½®åˆ»åº¦æ ‡ç­¾

    # æ·»åŠ å…·ä½“æ•°å€¼æ ‡ç­¾
    for i, (angle, value) in enumerate(zip(angles[:-1], values_director[:-1])):
        text_val = ""
        if categories[i] == 'ç”µå½±æ•°é‡':
            text_val = f'{total_movies:.0f}éƒ¨'
        elif categories[i] == 'å¹³å‡è¯„åˆ†':
            text_val = f'{avg_douban_score:.1f}åˆ†'
        elif categories[i] == 'å¹³å‡ç‰‡é•¿':
            text_val = f'{avg_length:.0f}åˆ†é’Ÿ'
        elif categories[i] == 'å¹³å‡è¯„è®ºæ•°':
            text_val = f'{avg_comments:.0f}'  # æ˜¾ç¤ºåŸå§‹å¹³å‡è¯„è®ºæ•°ï¼Œä¸è½¬ä¸ºä¸‡

        if value * 1.15 > ax.get_rmax():
            ax.set_rmax(value * 1.2)

        ax.text(angle, value * 1.15, text_val, color='black', size=10,
                horizontalalignment='center' if angle % (pi / 2) == 0 else ('left' if 0 < angle < pi else 'right'),
                verticalalignment='center' if angle == 0 else ('bottom' if 0 < angle < pi else 'top'))

    ax.set_title(f'å¯¼æ¼” {director_name} å½±å“åŠ›é›·è¾¾å›¾ (ç›¸å¯¹äºå¹³å‡æ°´å¹³)', va='bottom', fontsize=16)
    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))

    st.pyplot(fig)


# --- è¯äº‘ç”Ÿæˆè¾…åŠ©å‡½æ•° ---
def generate_wordcloud(text_corpus, title="è¯äº‘", max_words=200, stopwords=None):
    if not text_corpus.strip():
        st.warning(f"{title} - è¯­æ–™ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
        return

    # æ·»åŠ ä¸€äº›å¸¸è§çš„ä¸­æ–‡åœç”¨è¯ï¼Œä»¥åŠå¯èƒ½æ¥è‡ªç”µå½±è¯­å½•çš„é€šç”¨è¯
    if stopwords is None:
        stopwords = set(STOPWORDS)
        custom_stopwords = {
            'çš„', 'æ˜¯', 'äº†', 'å’Œ', 'ä¹Ÿ', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ',
            'è¿™éƒ¨', 'ä¸€ä¸ª', 'ä¸€ç§', 'æ²¡æœ‰', 'å°±æ˜¯', 'æˆ‘ä»¬', 'ä»–ä»¬', 'å¥¹ä»¬', 'ä¸€ä¸ª', 'ä¸€äº›',
            'ä»€ä¹ˆ', 'å¦‚æ­¤', 'ç”µå½±', 'æ•…äº‹', 'äººç”Ÿ', 'æ—¶é—´', 'ä¸–ç•Œ', 'æ‰€æœ‰', 'ä¸€ä¸ª', 'ä¸€åœº',
            'ä¸€æ®µ', 'ç”Ÿæ´»', 'çˆ±', 'ä¸€åˆ‡', 'è‡ªå·±', 'æ°¸è¿œ', 'å¯ä»¥', 'ä¸ºäº†', 'å¦‚æœ', 'è¿™éƒ¨ç”µå½±'
        }
        stopwords.update(custom_stopwords)

    # ä¸­æ–‡åˆ†è¯
    seg_list = jieba.cut(text_corpus, cut_all=False)  # ç²¾ç¡®æ¨¡å¼
    filtered_words = [word for word in seg_list if len(word) > 1 and word not in stopwords]

    if not filtered_words:
        st.warning(f"{title} - åˆ†è¯åæ²¡æœ‰æœ‰æ•ˆè¯æ±‡ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
        return

    text = " ".join(filtered_words)

    wc = WordCloud(
        font_path='FZSTK.TTF',  # ç¡®ä¿è¿™é‡ŒæŒ‡å‘æ‚¨çš„ä¸­æ–‡TrueTypeå­—ä½“æ–‡ä»¶
        background_color="white",
        max_words=max_words,
        width=1000,
        height=600,
        margin=2,
        random_state=42,
        collocations=False,  # ä¸åŒ…å«è¯ç»„
        stopwords=stopwords
    )
    wc.generate(text)

    fig, ax = plt.subplots(figsize=(10, 6))
    ax.imshow(wc, interpolation='bilinear')
    ax.axis("off")
    ax.set_title(title, fontsize=18)
    st.pyplot(fig)


# --- ä¸»åº”ç”¨ç¨‹åºé€»è¾‘ ---
st.title("è±†ç“£ç”µå½±åˆ†æ - Top 250 ğŸ¬")
st.markdown("---")

st.sidebar.header("å¯¼èˆª")
# ç§»é™¤ç¥¨æˆ¿é¢„æµ‹é¡µé¢
page = st.sidebar.radio("é€‰æ‹©é¡µé¢", ["æ•°æ®æ¦‚è§ˆ", "æ¢ç´¢æ€§åˆ†æ", "å¯¼æ¼”å½±å“åŠ›åˆ†æ", "ç”µå½±è¯­å½•è¯äº‘"])

# åŠ è½½æ•°æ® (åœ¨æ‰€æœ‰é¡µé¢é€»è¾‘ä¹‹å‰åŠ è½½ä¸€æ¬¡)
processed_df = load_and_preprocess_data(db_connection)

if processed_df.empty:
    st.error("æ•°æ®åŠ è½½æˆ–é¢„å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“å’Œæ•°æ®ã€‚")
    st.stop()  # å¦‚æœæ•°æ®ä¸ºç©ºï¼Œåˆ™åœæ­¢åº”ç”¨ï¼Œé¿å…åç»­æŠ¥é”™

# === é¡µé¢1: æ•°æ®æ¦‚è§ˆ ===
if page == "æ•°æ®æ¦‚è§ˆ":
    st.header("ğŸ“Š æ•°æ®æ¦‚è§ˆ")

    # å…³é”®æŒ‡æ ‡å±•ç¤º
    col1, col2, col3 = st.columns(3)  # åªæœ‰3åˆ—æŒ‡æ ‡
    with col1:
        st.metric("ç”µå½±æ€»æ•°", len(processed_df))
    with col2:
        st.metric("å¹³å‡è¯„åˆ†", f"{processed_df['è±†ç“£è¯„åˆ†'].mean():.2f}")
    with col3:
        min_year = processed_df['ä¸Šæ˜ å¹´ä»½'].min() if not processed_df['ä¸Šæ˜ å¹´ä»½'].empty else 'N/A'
        max_year = processed_df['ä¸Šæ˜ å¹´ä»½'].max() if not processed_df['ä¸Šæ˜ å¹´ä»½'].empty else 'N/A'
        st.metric("å¹´ä»½èŒƒå›´", f"{min_year}-{max_year}")

    st.subheader("æ•°æ®è¡¨é¢„è§ˆ")
    # æ˜¾ç¤ºéƒ¨åˆ†æ ¸å¿ƒåˆ—
    display_cols = ['ç”µå½±å', 'è±†ç“£è¯„åˆ†', 'è±†ç“£è¯„è®ºæ•°', 'ä¸Šæ˜ å¹´ä»½', 'æ—¶é•¿', 'å¯¼æ¼”_list', 'ç±»å‹_list', 'ç”µå½±è¯­å½•']
    available_cols = [col for col in display_cols if col in processed_df.columns]
    st.dataframe(processed_df[available_cols].head(10))

    st.subheader("æ•°æ®åˆ†å¸ƒç»Ÿè®¡")
    numeric_cols = ['è±†ç“£è¯„åˆ†', 'è±†ç“£è¯„è®ºæ•°', 'æ—¶é•¿']  # ç§»é™¤ç¥¨æˆ¿ã€åœºå‡äººæ•°
    available_numeric = [col for col in numeric_cols if col in processed_df.columns]
    if available_numeric:
        st.dataframe(processed_df[available_numeric].describe().transpose())
    else:
        st.warning("æ— å¯ç”¨çš„æ•°å€¼åˆ—è¿›è¡Œç»Ÿè®¡æè¿°ã€‚")

# === é¡µé¢2: æ¢ç´¢æ€§åˆ†æ ===
elif page == "æ¢ç´¢æ€§åˆ†æ":
    st.header("ğŸ” æ¢ç´¢æ€§æ•°æ®åˆ†æ")

    # è¯„åˆ†åˆ†å¸ƒ
    st.subheader("ç”µå½±è¯„åˆ†åˆ†å¸ƒåˆ†æ")
    col1, col2 = st.columns(2)

    with col1:
        if 'è±†ç“£è¯„åˆ†' in processed_df.columns:
            fig_hist = px.histogram(processed_df, x='è±†ç“£è¯„åˆ†', nbins=20,
                                    title='è±†ç“£è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾',
                                    labels={'è±†ç“£è¯„åˆ†': 'è±†ç“£è¯„åˆ†', 'count': 'ç”µå½±æ•°é‡'})
            st.plotly_chart(fig_hist, use_container_width=True)
        else:
            st.warning("è±†ç“£è¯„åˆ†æ•°æ®ä¸å¯ç”¨ã€‚")

    with col2:
        if 'è±†ç“£è¯„è®ºæ•°' in processed_df.columns and 'è±†ç“£è¯„åˆ†' in processed_df.columns:
            # è¯„åˆ† vs è¯„è®ºæ•°æ•£ç‚¹å›¾
            fig_scatter = px.scatter(processed_df, x='è±†ç“£è¯„è®ºæ•°', y='è±†ç“£è¯„åˆ†',
                                     hover_data=['ç”µå½±å'] if 'ç”µå½±å' in processed_df.columns else None,
                                     title='è±†ç“£è¯„è®ºæ•° vs è±†ç“£è¯„åˆ†',
                                     log_x=True)  # è¯„è®ºæ•°å¯èƒ½åˆ†å¸ƒå¾ˆå¹¿ï¼Œç”¨å¯¹æ•°è½´æ›´æ¸…æ™°
            st.plotly_chart(fig_scatter, use_container_width=True)
        else:
            st.warning("è±†ç“£è¯„è®ºæ•°æˆ–è±†ç“£è¯„åˆ†æ•°æ®ä¸å¯ç”¨ã€‚")

    # å¹´åº¦ç”µå½±æ•°é‡å’Œå¹³å‡è¯„åˆ†è¶‹åŠ¿
    st.subheader("å¹´åº¦ç”µå½±æ•°é‡ä¸å¹³å‡è¯„åˆ†è¶‹åŠ¿")
    if 'ä¸Šæ˜ å¹´ä»½' in processed_df.columns and 'è±†ç“£è¯„åˆ†' in processed_df.columns:
        yearly_stats = processed_df.groupby('ä¸Šæ˜ å¹´ä»½').agg(
            ç”µå½±æ•°é‡=('ç”µå½±å', 'count') if 'ç”µå½±å' in processed_df.columns else ('è±†ç“£è¯„åˆ†', 'count'),
            å¹³å‡è¯„åˆ†=('è±†ç“£è¯„åˆ†', 'mean')
        ).reset_index()
        yearly_stats = yearly_stats[yearly_stats['ä¸Šæ˜ å¹´ä»½'] > 1900]  # è¿‡æ»¤ä¸åˆç†çš„å¹´ä»½

        if not yearly_stats.empty:
            fig_yearly = make_subplots(
                rows=1, cols=2,
                subplot_titles=('å¹´åº¦ç”µå½±æ•°é‡', 'å¹´åº¦å¹³å‡è¯„åˆ†'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}]]
            )

            fig_yearly.add_trace(go.Scatter(x=yearly_stats['ä¸Šæ˜ å¹´ä»½'], y=yearly_stats['ç”µå½±æ•°é‡'],
                                            name='ç”µå½±æ•°é‡', line=dict(color='red')), row=1, col=1)
            fig_yearly.add_trace(go.Scatter(x=yearly_stats['ä¸Šæ˜ å¹´ä»½'], y=yearly_stats['å¹³å‡è¯„åˆ†'],
                                            name='å¹³å‡è¯„åˆ†', line=dict(color='purple')), row=1, col=2)

            fig_yearly.update_layout(height=400, showlegend=False, title_text="å¹´åº¦ç”µå½±å¸‚åœºè¶‹åŠ¿åˆ†æ")
            st.plotly_chart(fig_yearly, use_container_width=True)
        else:
            st.warning("å¹´åº¦è¶‹åŠ¿æ•°æ®ä¸è¶³ä»¥ç»˜åˆ¶å›¾è¡¨ã€‚")
    else:
        st.warning("å¹´åº¦è¶‹åŠ¿åˆ†ææ‰€éœ€æ•°æ®ï¼ˆä¸Šæ˜ å¹´ä»½ã€è¯„åˆ†ï¼‰ä¸å¯ç”¨ã€‚")

    # ç±»å‹åˆ†æ
    st.subheader("ç”µå½±ç±»å‹åˆ†æ")
    if 'ç±»å‹_list' in processed_df.columns and 'è±†ç“£è¯„åˆ†' in processed_df.columns:
        all_genres = [genre for sublist in processed_df['ç±»å‹_list'] for genre in sublist]
        genre_counts = pd.Series(all_genres).value_counts().head(15)

        col1, col2 = st.columns(2)
        with col1:
            fig_genre_bar = px.bar(x=genre_counts.values, y=genre_counts.index,
                                   orientation='h', title='ç”µå½±ç±»å‹åˆ†å¸ƒ',
                                   labels={'x': 'ç”µå½±æ•°é‡', 'y': 'ç±»å‹'})
            st.plotly_chart(fig_genre_bar, use_container_width=True)

        with col2:
            # ç±»å‹å¹³å‡è¯„åˆ†
            genre_scores = {}
            for idx, genres in processed_df['ç±»å‹_list'].items():
                score = processed_df.loc[idx, 'è±†ç“£è¯„åˆ†']
                for genre in genres:
                    if genre not in genre_scores:
                        genre_scores[genre] = []
                    genre_scores[genre].append(score)

            MIN_MOVIES_FOR_AVG = 5  # è‡³å°‘5éƒ¨ç”µå½±æ‰èƒ½è®¡ç®—å¹³å‡åˆ†
            genre_avg_score = {k: np.mean(v) for k, v in genre_scores.items() if len(v) >= MIN_MOVIES_FOR_AVG}
            genre_avg_score = dict(sorted(genre_avg_score.items(), key=lambda x: x[1], reverse=True)[:10])

            if genre_avg_score:
                fig_genre_avg = px.bar(x=list(genre_avg_score.values()), y=list(genre_avg_score.keys()),
                                       orientation='h', title=f'å„ç±»å‹å¹³å‡è¯„åˆ†Top10 (è‡³å°‘{MIN_MOVIES_FOR_AVG}éƒ¨ç”µå½±)',
                                       labels={'x': 'å¹³å‡è¯„åˆ†', 'y': 'ç±»å‹'})
                st.plotly_chart(fig_genre_avg, use_container_width=True)
            else:
                st.info("æ²¡æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—ç±»å‹å¹³å‡è¯„åˆ†ã€‚")
    else:
        st.warning("ç±»å‹æ•°æ®æˆ–è±†ç“£è¯„åˆ†æ•°æ®ä¸å¯ç”¨ã€‚")

    # ç”µå½±æ—¶é•¿åˆ†å¸ƒ
    st.subheader("ç”µå½±æ—¶é•¿åˆ†å¸ƒ")
    if 'æ—¶é•¿' in processed_df.columns:
        fig_duration = px.histogram(processed_df, x='æ—¶é•¿', nbins=30,
                                    title='ç”µå½±æ—¶é•¿åˆ†å¸ƒç›´æ–¹å›¾',
                                    labels={'æ—¶é•¿': 'æ—¶é•¿(åˆ†é’Ÿ)', 'count': 'ç”µå½±æ•°é‡'})
        st.plotly_chart(fig_duration, use_container_width=True)
    else:
        st.warning("ç”µå½±æ—¶é•¿æ•°æ®ä¸å¯ç”¨ã€‚")


# === é¡µé¢3: å¯¼æ¼”å½±å“åŠ›åˆ†æ ===
elif page == "å¯¼æ¼”å½±å“åŠ›åˆ†æ":
    st.header("ğŸ¬ å¯¼æ¼”å½±å“åŠ›åˆ†æ")

    if 'å¯¼æ¼”_list' in processed_df.columns and 'è±†ç“£è¯„åˆ†' in processed_df.columns and 'è±†ç“£è¯„è®ºæ•°' in processed_df.columns:
        all_directors = [d for sublist in processed_df['å¯¼æ¼”_list'] for d in sublist]
        director_stats = {}

        for director in set(all_directors):
            director_movies = processed_df[processed_df['å¯¼æ¼”_list'].apply(lambda x: director in x)]
            if len(director_movies) >= 2:  # è‡³å°‘2éƒ¨ç”µå½±ï¼Œæ•°æ®æ›´æœ‰æ„ä¹‰
                director_stats[director] = {
                    'ç”µå½±æ•°é‡': len(director_movies),
                    'å¹³å‡è¯„åˆ†': director_movies['è±†ç“£è¯„åˆ†'].mean(),
                    'å¹³å‡æ—¶é•¿': director_movies['æ—¶é•¿'].mean(),
                    'æ€»è¯„è®ºæ•°': director_movies['è±†ç“£è¯„è®ºæ•°'].sum()
                }

        director_df = pd.DataFrame(director_stats).T.reset_index()
        director_df.columns = ['å¯¼æ¼”', 'ç”µå½±æ•°é‡', 'å¹³å‡è¯„åˆ†', 'å¹³å‡æ—¶é•¿', 'æ€»è¯„è®ºæ•°']
        # æ’åºä»¥æ€»è¯„è®ºæ•°æˆ–ç”µå½±æ•°é‡
        director_df = director_df.sort_values('æ€»è¯„è®ºæ•°', ascending=False)

        if not director_df.empty:
            # é¡¶çº§å¯¼æ¼”æ’è¡Œæ¦œ
            st.subheader("ğŸ“Š å¯¼æ¼”æ’è¡Œæ¦œ")

            tab1, tab2, tab3 = st.tabs(["ç”µå½±æ•°é‡æ’è¡Œ", "å¹³å‡è¯„åˆ†æ’è¡Œ", "æ€»è¯„è®ºæ•°æ’è¡Œ"])

            with tab1:
                top_directors_count = director_df.sort_values('ç”µå½±æ•°é‡', ascending=False).head(15)
                fig_director_count = px.bar(top_directors_count, x='ç”µå½±æ•°é‡', y='å¯¼æ¼”',
                                            orientation='h', title='å¯¼æ¼”ç”µå½±æ•°é‡Top15',
                                            labels={'ç”µå½±æ•°é‡': 'ç”µå½±æ•°é‡', 'å¯¼æ¼”': 'å¯¼æ¼”'})
                st.plotly_chart(fig_director_count, use_container_width=True)

            with tab2:
                # è¿‡æ»¤å‡ºè‡³å°‘3éƒ¨ç”µå½±çš„å¯¼æ¼”ï¼Œä½¿å¾—å¹³å‡è¯„åˆ†æ›´å…·ä»£è¡¨æ€§
                top_directors_avg_score = director_df[director_df['ç”µå½±æ•°é‡'] >= 3].sort_values('å¹³å‡è¯„åˆ†',
                                                                                                ascending=False).head(
                    15)
                fig_director_avg_score = px.bar(top_directors_avg_score, x='å¹³å‡è¯„åˆ†', y='å¯¼æ¼”',
                                                orientation='h', title='å¯¼æ¼”å¹³å‡è¯„åˆ†Top15 (è‡³å°‘3éƒ¨ç”µå½±)',
                                                labels={'å¹³å‡è¯„åˆ†': 'å¹³å‡è¯„åˆ†', 'å¯¼æ¼”': 'å¯¼æ¼”'})
                st.plotly_chart(fig_director_avg_score, use_container_width=True)

            with tab3:
                top_directors_comments = director_df.sort_values('æ€»è¯„è®ºæ•°', ascending=False).head(15)
                fig_director_comments = px.bar(top_directors_comments, x='æ€»è¯„è®ºæ•°', y='å¯¼æ¼”',
                                               orientation='h', title='å¯¼æ¼”æ€»è¯„è®ºæ•°Top15',
                                               labels={'æ€»è¯„è®ºæ•°': 'æ€»è¯„è®ºæ•°', 'å¯¼æ¼”': 'å¯¼æ¼”'})
                st.plotly_chart(fig_director_comments, use_container_width=True)

            # å¯¼æ¼”è¯¦ç»†åˆ†æ
            st.subheader("ğŸ” å¯¼æ¼”è¯¦ç»†åˆ†æ")

            # å¯¼æ¼”é€‰æ‹©å™¨
            available_directors = sorted(director_df['å¯¼æ¼”'].tolist())
            selected_director = st.selectbox("é€‰æ‹©å¯¼æ¼”è¿›è¡Œè¯¦ç»†åˆ†æ:", available_directors)

            if selected_director:
                director_movies = processed_df[processed_df['å¯¼æ¼”_list'].apply(lambda x: selected_director in x)]

                # å¯¼æ¼”åŸºæœ¬ä¿¡æ¯
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ç”µå½±æ•°é‡", len(director_movies))
                with col2:
                    st.metric("å¹³å‡è¯„åˆ†", f"{director_movies['è±†ç“£è¯„åˆ†'].mean():.1f}")
                with col3:
                    st.metric("æ€»è¯„è®ºæ•°", f"{director_movies['è±†ç“£è¯„è®ºæ•°'].sum():,.0f}")

                # å¯¼æ¼”ç”µå½±åˆ—è¡¨
                st.subheader(f"{selected_director} çš„ç”µå½±ä½œå“")
                movie_cols = ['ç”µå½±å', 'è±†ç“£è¯„åˆ†', 'è±†ç“£è¯„è®ºæ•°', 'ä¸Šæ˜ å¹´ä»½', 'æ—¶é•¿']
                available_movie_cols = [col for col in movie_cols if col in director_movies.columns]

                display_movies = director_movies[available_movie_cols].sort_values('è±†ç“£è¯„åˆ†', ascending=False)
                st.dataframe(display_movies, use_container_width=True)

                # å¯¼æ¼”ä½œå“è¶‹åŠ¿åˆ†æ
                if len(director_movies) >= 3:  # è‡³å°‘3éƒ¨ç”µå½±æ‰èƒ½çœ‹è¶‹åŠ¿
                    st.subheader(f"{selected_director} ä½œå“è¯„åˆ†è¶‹åŠ¿")

                    director_movies_sorted = director_movies.sort_values('ä¸Šæ˜ å¹´ä»½')

                    fig_trend = go.Figure()
                    fig_trend.add_trace(go.Scatter(x=director_movies_sorted['ä¸Šæ˜ å¹´ä»½'],
                                                   y=director_movies_sorted['è±†ç“£è¯„åˆ†'],
                                                   mode='lines+markers',
                                                   name='è±†ç“£è¯„åˆ†',
                                                   line=dict(color='orange')))

                    fig_trend.update_layout(height=400, title_text=f"{selected_director} ä½œå“å¹³å‡è¯„åˆ†è¶‹åŠ¿",
                                            showlegend=False)
                    st.plotly_chart(fig_trend, use_container_width=True)
                else:
                    st.info(f"å¯¼æ¼” {selected_director} ä½œå“æ•°é‡ä¸è¶³ï¼Œæ— æ³•ç»˜åˆ¶è¶‹åŠ¿å›¾ã€‚")

                # é›·è¾¾å›¾åˆ†æ
                st.subheader(f"{selected_director} å½±å“åŠ›é›·è¾¾å›¾")
                plot_director_radar_chart(selected_director, processed_df)

            # å¯¼æ¼”å¯¹æ¯”åˆ†æ
            st.subheader("ğŸ†š å¯¼æ¼”å¯¹æ¯”åˆ†æ")

            col1, col2 = st.columns(2)
            with col1:
                director1 = st.selectbox("é€‰æ‹©å¯¼æ¼”1:", available_directors, key="director1")
            with col2:
                director2 = st.selectbox("é€‰æ‹©å¯¼æ¼”2:", available_directors, key="director2",
                                         index=1 if len(available_directors) > 1 else 0)

            if director1 and director2 and director1 != director2:
                director1_movies = processed_df[processed_df['å¯¼æ¼”_list'].apply(lambda x: director1 in x)]
                director2_movies = processed_df[processed_df['å¯¼æ¼”_list'].apply(lambda x: director2 in x)]

                comparison_df = pd.DataFrame({
                    'æŒ‡æ ‡': ['ç”µå½±æ•°é‡', 'å¹³å‡è¯„åˆ†', 'å¹³å‡æ—¶é•¿(åˆ†é’Ÿ)', 'æ€»è¯„è®ºæ•°'],
                    director1: [
                        len(director1_movies),
                        director1_movies['è±†ç“£è¯„åˆ†'].mean(),
                        director1_movies['æ—¶é•¿'].mean(),
                        director1_movies['è±†ç“£è¯„è®ºæ•°'].sum()
                    ],
                    director2: [
                        len(director2_movies),
                        director2_movies['è±†ç“£è¯„åˆ†'].mean(),
                        director2_movies['æ—¶é•¿'].mean(),
                        director2_movies['è±†ç“£è¯„è®ºæ•°'].sum()
                    ]
                })

                st.dataframe(comparison_df.round(2), use_container_width=True)
            elif director1 == director2 and director1:
                st.warning("è¯·é€‰æ‹©ä¸¤ä½ä¸åŒçš„å¯¼æ¼”è¿›è¡Œå¯¹æ¯”ã€‚")
            else:
                st.info("è¯·é€‰æ‹©ä¸¤ä½å¯¼æ¼”è¿›è¡Œå¯¹æ¯”ã€‚")

        else:
            st.warning("æ²¡æœ‰è¶³å¤Ÿçš„å¯¼æ¼”æ•°æ®è¿›è¡Œåˆ†æã€‚")
    else:
        st.error("å¯¼æ¼”ç›¸å…³æ•°æ®ï¼ˆå¯¼æ¼”åˆ—è¡¨ã€è¯„åˆ†ã€è¯„è®ºæ•°ï¼‰ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æ•°æ®é¢„å¤„ç†ã€‚")

# === é¡µé¢4: ç”µå½±è¯­å½•è¯äº‘ ===
elif page == "ç”µå½±è¯­å½•è¯äº‘":
    st.header("â˜ï¸ ç”µå½±è¯­å½•è¯äº‘åˆ†æ")

    if 'ç”µå½±è¯­å½•' in processed_df.columns:
        all_quotes = " ".join(processed_df['ç”µå½±è¯­å½•'].dropna().astype(str).tolist())

        st.markdown("### è±†ç“£ Top 250 ç”µå½±è¯­å½•æ€»è§ˆè¯äº‘")
        generate_wordcloud(all_quotes, title="è±†ç“£ Top 250 ç”µå½±è¯­å½•è¯äº‘")

        st.markdown("---")
        st.subheader("æŒ‰ç”µå½±ç±»å‹ç”Ÿæˆè¯äº‘")
        if 'ç±»å‹_list' in processed_df.columns:
            all_types = [genre for sublist in processed_df['ç±»å‹_list'] for genre in sublist]
            unique_types = sorted(list(set(all_types)))

            if unique_types:
                selected_type = st.selectbox("é€‰æ‹©ç”µå½±ç±»å‹ï¼š", ['æ‰€æœ‰ç±»å‹'] + unique_types)

                if selected_type == 'æ‰€æœ‰ç±»å‹':
                    generate_wordcloud(all_quotes, title="æ‰€æœ‰ç”µå½±ç±»å‹è¯­å½•è¯äº‘")
                else:
                    type_quotes = processed_df[processed_df['ç±»å‹_list'].apply(lambda x: selected_type in x)][
                        'ç”µå½±è¯­å½•'].dropna().astype(str).tolist()
                    if type_quotes:
                        generate_wordcloud(" ".join(type_quotes), title=f"{selected_type} ç”µå½±è¯­å½•è¯äº‘")
                    else:
                        st.info(f"ç±»å‹ '{selected_type}' æ²¡æœ‰ç”µå½±è¯­å½•æ•°æ®ã€‚")
            else:
                st.warning("æ²¡æœ‰å¯ç”¨çš„ç”µå½±ç±»å‹æ•°æ®ã€‚")
        else:
            st.warning("ç”µå½±ç±»å‹æ•°æ®ä¸å¯ç”¨ã€‚")

    else:
        st.warning("æ•°æ®åº“ä¸­æ²¡æœ‰ 'ç”µå½±è¯­å½•' åˆ—ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")

# ä¾§è¾¹æ é¢å¤–ä¿¡æ¯
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“ˆ æ•°æ®æ´å¯Ÿ")

if not processed_df.empty:
    # æ˜¾ç¤ºä¸€äº›æœ‰è¶£çš„ç»Ÿè®¡
    highest_rated_col = 'è±†ç“£è¯„åˆ†'
    movie_name_col = 'ç”µå½±å'

    if highest_rated_col in processed_df.columns and not processed_df[highest_rated_col].empty:
        highest_rated = processed_df.loc[processed_df[highest_rated_col].idxmax()]
        st.sidebar.markdown(f"**æœ€é«˜è¯„åˆ†ç”µå½±:**")
        if movie_name_col in processed_df.columns:
            st.sidebar.write(f"ğŸ¬ {highest_rated.get(movie_name_col, 'N/A')}")
        st.sidebar.write(f"â­ {highest_rated[highest_rated_col]:.1f}åˆ†")
    else:
        st.sidebar.info("æœ€é«˜è¯„åˆ†ç”µå½±æ•°æ®ä¸å¯ç”¨ã€‚")

    # æ˜¾ç¤ºæ•°æ®æ›´æ–°æ—¶é—´
    st.sidebar.markdown("---")
    st.sidebar.markdown("**æ•°æ®è¯´æ˜:**")
    st.sidebar.write("â€¢ æ•°æ®æ¥æº: è±†ç“£ç”µå½± (Top 250)")
    st.sidebar.write("â€¢ åŒ…å«è¯„åˆ†ã€å¯¼æ¼”ã€ç±»å‹ã€è¯­å½•ç­‰ä¿¡æ¯")
    st.sidebar.write("â€¢ ä¸“æ³¨äºç”µå½±ç‰¹æ€§å’Œå½±å“åŠ›åˆ†æ")
else:
    st.sidebar.warning("æš‚æ— æ•°æ®å¯ä¾›åˆ†æã€‚")

# é¡µè„š
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>ğŸ¬ è±†ç“£ç”µå½±åˆ†æç³»ç»Ÿ | åŸºäº Top 250 æ•°æ®çš„æ´å¯Ÿ ğŸ“Š</p>
        <p><small>æ•°æ®é©±åŠ¨å†³ç­–ï¼ŒåŠ©åŠ›ç”µå½±çˆ±å¥½è€…å‘ç°å¥½ç‰‡</small></p>
    </div>
    """,
    unsafe_allow_html=True
)