# maoyan_scraper.py

import requests
import lxml.html
import time
import re
from urllib.parse import quote
from requests.exceptions import RequestException
import random
import traceback

# --- å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— ---
from database import get_db_connection, store_maoyan_movie
from movie_parser import parse_maoyan_rankings, find_best_match_from_douban_search, get_douban_detail_data

# --- å…¨å±€é…ç½®ä¸è¯·æ±‚å¤´ ---
MAOYAN_URL = 'https://piaofang.maoyan.com/rankings/year'
DOUBAN_SEARCH_URL = 'https://www.douban.com/search?cat=1002&q='
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
    'Cookie': '__utmv=30149280.26588; _vwo_uuid_v2=DAC63BADB41673F0603FA177C6F5344C6|23d9f2799e7e65cc292a49365de88a9c; __utma=30149280.2038156265.1708787605.1721631000.1727963319.9; __utma=223695111.1132091569.1709467909.1715697793.1727963319.4; bid=i3lhJgsUsJk; ll="118174"; dbcl2="265884385:DBbxLcXmPq0"; push_noty_num=0; push_doumail_num=0; ck=ATer; frodotk_db="54011ed41ddd306dfc035c7c59979147"; ap_v=0,6.0',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
    'Referer': 'https://www.douban.com/'
}


def get_html(url: str, retries: int = 3) -> str:
    """å¥å£®çš„HTMLè·å–å‡½æ•°"""
    delay = random.uniform(0.5, 1)
    print(f"  ğŸŒ  æ­£åœ¨è¯·æ±‚: {url} (å»¶è¿Ÿ {delay:.2f}s)")
    time.sleep(delay)
    for attempt in range(retries):
        try:
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.raise_for_status()
            if len(response.text) < 1000: raise RequestException("è·å–åˆ°çš„HTMLå†…å®¹è¿‡çŸ­")
            return response.text
        except RequestException as e:
            print(f"  âŒ  ç½‘ç»œè¯·æ±‚å¤±è´¥ (ç¬¬ {attempt + 1} æ¬¡å°è¯•): {e}")
            if attempt < retries - 1: time.sleep(5 * (attempt + 1))
    return ""


def get_search_url(text: str) -> str:
    return DOUBAN_SEARCH_URL + quote(text)


def main():
    db_conn = get_db_connection()
    if not db_conn: return

    print("--- å¼€å§‹çˆ¬å–çŒ«çœ¼ç¥¨æˆ¿æ¦œå• ---")
    maoyan_html = get_html(MAOYAN_URL)
    maoyan_movies = parse_maoyan_rankings(maoyan_html)

    if not maoyan_movies:
        print("âŒ æœªèƒ½ä»çŒ«çœ¼ç¥¨æˆ¿æ¦œè·å–ä»»ä½•ç”µå½±æ•°æ®ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        return

    print(f"âœ”ï¸  æˆåŠŸä»çŒ«çœ¼è·å– {len(maoyan_movies)} éƒ¨ç”µå½±åŸºç¡€æ•°æ®ã€‚")

    for i, movie_base in enumerate(maoyan_movies):
        print(f"\n--- æ­£åœ¨å¤„ç†ç¬¬ {i + 1}/{len(maoyan_movies)} éƒ¨ç”µå½±: {movie_base['name']} ---")
        try:
            # 1. è±†ç“£æœç´¢
            search_year = int(movie_base['release_date'].split('-')[0])
            search_query = f"({search_year}) {movie_base['name']}"
            print(f"  ğŸ”  æ­£åœ¨è±†ç“£æœç´¢: '{search_query}'")
            search_html = get_html(get_search_url(search_query))
            if not search_html: continue

            douban_match = find_best_match_from_douban_search(search_html)

            # 2. åˆå§‹åŒ–æœ€ç»ˆæ•°æ®å­—å…¸
            full_data = {**movie_base, "douban_id": None, "douban_score": 0.0, "douban_comment_count": 0,
                         "cover_url": "", "synopsis": "", "comments_json": "[]", "directors": [], "actors": [],
                         "genres": [], "name_en": "", "quote": "-", "release_date_text": "", "runtime_text": "",
                         "year": search_year, "douban_url": ""}

            # 3. æ·±å…¥çˆ¬å–è¯¦æƒ…é¡µ
            if douban_match and douban_match.get("douban_url"):
                print(f"  âœ”ï¸  æ‰¾åˆ°åŒ¹é…é¡¹ï¼Œæ­£åœ¨æ·±å…¥è¯¦æƒ…é¡µ...")
                full_data.update(douban_match)

                detail_html = get_html(douban_match["douban_url"])
                if detail_html:
                    # get_douban_detail_dataä¼šè¿”å›åŒ…å«genresçš„å­—å…¸
                    douban_detail_data = get_douban_detail_data(detail_html)
                    # updateä¼šæŠŠgenresåˆ—è¡¨æ›´æ–°åˆ°full_dataä¸­
                    full_data.update(douban_detail_data)
                    print(f"  âœ”ï¸  æˆåŠŸè§£æè±†ç“£è¯¦æƒ…é¡µï¼Œç±»å‹: {full_data.get('genres')}")
            else:
                print(f"  âŒ  åœ¨è±†ç“£æœªæ‰¾åˆ°åŒ¹é…é¡¹ã€‚")

            # 4. å­˜å…¥æ•°æ®åº“
            # store_maoyan_movieç°åœ¨å¯ä»¥æ­£ç¡®å¤„ç†full_dataä¸­åŒ…å«çš„genresåˆ—è¡¨
            store_maoyan_movie(db_conn, full_data)

        except Exception:
            print(f"  ğŸ’¥  å¤„ç†ç”µå½± '{movie_base.get('name')}' æ—¶å‘ç”ŸæœªçŸ¥ä¸¥é‡é”™è¯¯:")
            traceback.print_exc()
            continue

    if db_conn:
        db_conn.close()
        print("\nâœ”ï¸  æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæ•°æ®åº“è¿æ¥å·²å…³é—­ã€‚")


if __name__ == "__main__":
    main()