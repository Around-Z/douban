import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pymysql
import warnings
from math import pi
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
# import jieba # æš‚æ—¶æœªä½¿ç”¨ï¼Œå¯æŒ‰éœ€ä¿ç•™
# from wordcloud import WordCloud # æš‚æ—¶æœªä½¿ç”¨ï¼Œå¯æŒ‰éœ€ä¿ç•™
from collections import Counter

# --- Streamlit é¡µé¢é…ç½® (å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤) ---
st.set_page_config(layout="wide", page_title="ç”µå½±ç¥¨æˆ¿åˆ†æä¸é¢„æµ‹")

# è®¾ç½® Matplotlib å­—ä½“ä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']  # æˆ–è€… 'Microsoft YaHei'ï¼Œæ ¹æ®æ‚¨çš„ç³»ç»Ÿå­—ä½“é€‰æ‹©
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜


# --- æ•°æ®åº“è¿æ¥ (ä½¿ç”¨ Streamlit ç¼“å­˜èµ„æºï¼Œé¿å…æ¯æ¬¡è¿è¡Œéƒ½é‡æ–°è¿æ¥) ---
@st.cache_resource
def get_database_connection_resource():
    """è·å–å¹¶ç¼“å­˜æ•°æ®åº“è¿æ¥"""
    try:
        # è¯·æ ¹æ®æ‚¨çš„å®é™…MySQLé…ç½®ä¿®æ”¹è¿™äº›å‚æ•°
        db = pymysql.connect(host='localhost',
                             user='root',
                             password='',
                             database='douban',
                             charset='utf8mb4')
        st.success("æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
        return db
    except pymysql.err.OperationalError as e:
        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥ (è¯·æ£€æŸ¥MySQLæœåŠ¡æˆ–è¿æ¥å‚æ•°): {e}")
        st.stop()  # åœæ­¢åº”ç”¨è¿è¡Œï¼Œç›´åˆ°é—®é¢˜è§£å†³
    except Exception as e:
        st.error(f"å‘ç”ŸæœªçŸ¥æ•°æ®åº“é”™è¯¯: {e}")
        st.stop()


db_connection = get_database_connection_resource()


# --- æ•°æ®åŠ è½½ä¸é¢„å¤„ç† (ä½¿ç”¨ Streamlit ç¼“å­˜æ•°æ®) ---
@st.cache_data(ttl=3600)  # æ•°æ®ç¼“å­˜1å°æ—¶
def load_and_preprocess_data(_db_conn) -> pd.DataFrame:
    """ä»æ•°æ®åº“åŠ è½½æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹"""
    st.info("æ­£åœ¨åŠ è½½å’Œé¢„å¤„ç†ç”µå½±æ•°æ®...")

    try:
        # å¿½ç•¥SQLalchemyçš„è­¦å‘Šï¼Œå› ä¸ºæˆ‘ä»¬ç›´æ¥ç”¨pymysql
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            df = pd.read_sql(f'SELECT * FROM `maoyan_movie`', _db_conn)
        st.success(f"æˆåŠŸä» 'maoyan_movie' è¡¨åŠ è½½ {len(df)} è¡Œæ•°æ®ã€‚")
        if df.empty:
            st.warning("maoyan_movie è¡¨ä¸­æ²¡æœ‰æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«å¡«å……æ•°æ®ã€‚")
            return pd.DataFrame()  # è¿”å›ç©ºDataFrame
    except Exception as e:
        st.error(f"ä»è¡¨ 'maoyan_movie' åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

    df = df.copy()  # åˆ›å»ºå‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning

    # 1. ä¸Šæ˜ æ—¥æœŸå¤„ç†
    df['ä¸Šæ˜ æ—¥æœŸ'] = pd.to_datetime(df['ä¸Šæ˜ æ—¥æœŸ'], errors='coerce')
    if df['ä¸Šæ˜ æ—¥æœŸ'].isnull().any():
        st.warning("è­¦å‘Š: 'ä¸Šæ˜ æ—¥æœŸ' åˆ—ä¸­å­˜åœ¨æ— æ³•è§£æçš„æ—¥æœŸï¼Œå·²è½¬æ¢ä¸º NaTã€‚")

    # æå–æ—¶é—´ç‰¹å¾
    df['ä¸Šæ˜ å¹´ä»½'] = df['ä¸Šæ˜ æ—¥æœŸ'].dt.year.fillna(-1).astype(int)
    df['ä¸Šæ˜ æœˆä»½'] = df['ä¸Šæ˜ æ—¥æœŸ'].dt.month.fillna(-1).astype(int)
    df['ä¸Šæ˜ æ—¥'] = df['ä¸Šæ˜ æ—¥æœŸ'].dt.day.fillna(-1).astype(int)
    df['ä¸Šæ˜ æ˜ŸæœŸå‡ '] = df['ä¸Šæ˜ æ—¥æœŸ'].dt.dayofweek.fillna(-1).astype(int)  # 0=æ˜ŸæœŸä¸€, 6=æ˜ŸæœŸæ—¥
    df['æ˜¯å¦å‘¨æœ«'] = df['ä¸Šæ˜ æ˜ŸæœŸå‡ '].isin([5, 6]).astype(int)  # 5:å‘¨å…­, 6:å‘¨æ—¥

    # 2. å¤„ç†å¤šå€¼åˆ†ç±»ç‰¹å¾ ('å¯¼æ¼”', 'æ¼”å‘˜', 'ç±»å‹', 'åœ°åŒº', 'è¯­è¨€')
    # åˆ›å»º '_list' ç»“å°¾çš„æ–°åˆ—æ¥å­˜å‚¨åˆ—è¡¨å½¢å¼çš„æ•°æ®ï¼Œè¿™äº›åˆ—ä¼šä¿ç•™ç”¨äºEDA
    original_multi_value_cols = ['å¯¼æ¼”', 'æ¼”å‘˜', 'ç±»å‹', 'åœ°åŒº', 'è¯­è¨€']
    for col in original_multi_value_cols:
        if col in df.columns:  # ç¡®ä¿åˆ—å­˜åœ¨
            df[col + '_list'] = df[col].apply(
                lambda x: [item.strip() for item in str(x).split(',') if item.strip()] if pd.notnull(x) else []
            )
        else:
            df[col + '_list'] = [[]] * len(df)  # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºç©ºåˆ—è¡¨åˆ—
            st.warning(f"è­¦å‘Š: æ•°æ®åº“ä¸­ç¼ºå°‘åˆ— '{col}'ã€‚å·²åˆ›å»ºç©ºåˆ—è¡¨åˆ—ã€‚")

    # --- 3. è½¬æ¢æ ¸å¿ƒæ•°å€¼ç‰¹å¾ä¸ºæ­£ç¡®çš„ç±»å‹å¹¶å¤„ç†ç¼ºå¤±å€¼ ---
    numeric_cols_to_convert = {
        'è±†ç“£è¯„åˆ†': float,
        'è±†ç“£è¯„è®ºæ•°': int,
        'æ—¶é•¿': int,
        'ç¥¨æˆ¿(ä¸‡å…ƒ)': float,
        'åœºå‡äººæ•°': float  # å‡è®¾ 'åœºå‡äººæ•°' åˆ—å­˜åœ¨
    }

    for col, dtype in numeric_cols_to_convert.items():
        if col in df.columns:
            # å°è¯•å°†åˆ—è½¬æ¢ä¸ºæ•°å­—ç±»å‹ï¼Œæ— æ³•è½¬æ¢çš„å˜ä¸ºNaN
            df[col] = pd.to_numeric(df[col], errors='coerce')
            # å¡«å……NaNå€¼ï¼šæµ®ç‚¹æ•°ç”¨0.0ï¼Œæ•´æ•°ç”¨0
            df[col] = df[col].fillna(0.0 if dtype == float else 0)
            # å†æ¬¡å¼ºåˆ¶è½¬æ¢ä¸ºç›®æ ‡ç±»å‹
            try:
                df[col] = df[col].astype(dtype)
            except Exception as e:
                st.error(f"ä¸¥é‡é”™è¯¯: åˆ— '{col}' æ— æ³•è½¬æ¢ä¸º {dtype} ç±»å‹ã€‚è¯·æ£€æŸ¥æ•°æ®æºä¸­è¯¥åˆ—çš„éæ•°å­—æˆ–åˆ—è¡¨å€¼ã€‚")
                # å¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œå°†è¯¥åˆ—è®¾ä¸ºå…¨é›¶ä»¥é¿å…åç»­å´©æºƒï¼Œä½†è¿™è¡¨ç¤ºæ•°æ®è´¨é‡é—®é¢˜
                df[col] = 0.0 if dtype == float else 0
        else:
            df[col] = 0.0 if dtype == float else 0  # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå¹¶å¡«å……é»˜è®¤å€¼
            st.warning(f"è­¦å‘Š: æ•°æ®åº“ä¸­ç¼ºå°‘åˆ— '{col}'ã€‚å·²åˆ›å»ºå¹¶å¡«å……é»˜è®¤å€¼ã€‚")

    # è¿‡æ»¤æ‰ä¸é€‚åˆåˆ†ææˆ–é¢„æµ‹çš„ç”µå½±
    initial_rows = len(df)
    # ç¥¨æˆ¿ä¸º0æˆ–NaNçš„è¿‡æ»¤
    df = df[df['ç¥¨æˆ¿(ä¸‡å…ƒ)'] > 0]
    # è±†ç“£è¯„åˆ†å¤§äº0ä¸”å°äºç­‰äº10
    df = df[(df['è±†ç“£è¯„åˆ†'] > 0) & (df['è±†ç“£è¯„åˆ†'] <= 10)]
    # è¯„è®ºæ•°å¤§äº0
    df = df[df['è±†ç“£è¯„è®ºæ•°'] > 0]
    # æ—¶é•¿å¤§äº0
    df = df[df['æ—¶é•¿'] > 0]
    # è¿‡æ»¤æ‰æœªæ¥ä¸Šæ˜ çš„ç”µå½±ï¼Œæˆ–è€…ä¸Šæ˜ å¹´ä»½æ˜æ˜¾ä¸åˆç†ï¼ˆæ¯”å¦‚-1ï¼‰çš„
    current_year = pd.Timestamp.now().year
    df = df[df['ä¸Šæ˜ å¹´ä»½'].isin(range(1900, current_year + 1))]  # é™åˆ¶å¹´ä»½èŒƒå›´

    st.write(
        f"å·²è¿‡æ»¤æ‰ {initial_rows - len(df)} è¡Œä¸é€‚åˆåˆ†ææˆ–é¢„æµ‹çš„ç”µå½±ï¼ˆä¾‹å¦‚ï¼šæœªæ¥ä¸Šæ˜ /ç¥¨æˆ¿0/è¯„åˆ†0/è¯„è®ºæ•°0/æ—¶é•¿0ï¼‰ã€‚å‰©ä½™ {len(df)} è¡Œã€‚")

    if df.empty:
        st.warning("è¿‡æ»¤åæ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚è¯·æ£€æŸ¥æ•°æ®æºå’Œè¿‡æ»¤æ¡ä»¶ã€‚")
        return pd.DataFrame()

    # --- 4. å¯¹é€‰å®šç‰¹å¾è¿›è¡Œ One-Hot ç¼–ç  ---
    # ç»Ÿè®¡å¹¶é€‰æ‹©Top Nï¼Œé¿å…ç”Ÿæˆè¿‡å¤šç‰¹å¾
    TOP_N_DIRECTORS = 30
    TOP_N_TYPES = 15
    TOP_N_PLACES = 10
    TOP_N_LANGS = 10

    all_directors = [d for sublist in df['å¯¼æ¼”_list'] for d in sublist]
    all_types = [t for sublist in df['ç±»å‹_list'] for t in sublist]
    all_places = [p for sublist in df['åœ°åŒº_list'] for p in sublist]
    all_langs = [l for sublist in df['è¯­è¨€_list'] for l in sublist]

    top_directors = pd.Series(all_directors).value_counts().head(TOP_N_DIRECTORS).index.tolist()
    top_types = pd.Series(all_types).value_counts().head(TOP_N_TYPES).index.tolist()
    top_places = pd.Series(all_places).value_counts().head(TOP_N_PLACES).index.tolist()
    top_langs = pd.Series(all_langs).value_counts().head(TOP_N_LANGS).index.tolist()

    def one_hot_encode_multi_value(df_col_list, top_items_list, prefix):
        """å¯¹å¤šå€¼ç‰¹å¾è¿›è¡ŒOne-Hotç¼–ç """
        # åˆ›å»ºä¸€ä¸ªç©ºDataFrameï¼Œåˆ—åä¸º 'prefix_item'
        temp_df = pd.DataFrame(0, index=df_col_list.index, columns=[f"{prefix}_{item}" for item in top_items_list])
        for idx, items in df_col_list.items():
            for item in items:
                col_name = f"{prefix}_{item}"
                if col_name in temp_df.columns:
                    temp_df.loc[idx, col_name] = 1
        return temp_df

    st.write("æ­£åœ¨è¿›è¡Œ One-Hot ç¼–ç ...")
    df_directors_ohe = one_hot_encode_multi_value(df['å¯¼æ¼”_list'], top_directors, 'å¯¼æ¼”')
    df_types_ohe = one_hot_encode_multi_value(df['ç±»å‹_list'], top_types, 'ç±»å‹')
    df_places_ohe = one_hot_encode_multi_value(df['åœ°åŒº_list'], top_places, 'åœ°åŒº')
    df_langs_ohe = one_hot_encode_multi_value(df['è¯­è¨€_list'], top_langs, 'è¯­è¨€')

    # å°†ç¼–ç åçš„ DataFrame åˆå¹¶å›ä¸» DataFrame
    df = pd.concat([df, df_directors_ohe, df_types_ohe, df_places_ohe, df_langs_ohe], axis=1)

    # --- 5. æ¸…ç†åŸå§‹å­—ç¬¦ä¸²åˆ— (ä¿ç•™_listç‰ˆæœ¬ç”¨äºEDAï¼Œåˆ é™¤åŸå§‹å­—ç¬¦ä¸²åˆ—) ---
    cols_to_drop_original_string = [col for col in original_multi_value_cols if col in df.columns]
    df.drop(columns=cols_to_drop_original_string, inplace=True)

    st.success("æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹å®Œæˆã€‚")
    return df


# --- å¯¼æ¼”å½±å“åŠ›é›·è¾¾å›¾è¾…åŠ©å‡½æ•° ---
def plot_director_radar_chart(director_name, processed_df):
    """ç»˜åˆ¶å¯¼æ¼”å½±å“åŠ›é›·è¾¾å›¾"""
    director_movies = processed_df[processed_df['å¯¼æ¼”_list'].apply(lambda x: director_name in x)]

    if director_movies.empty:
        st.warning(f"æ•°æ®é›†ä¸­æœªæ‰¾åˆ°å¯¼æ¼” '{director_name}' çš„ç”µå½±ä¿¡æ¯ã€‚")
        return

    # è®¡ç®—å¯¼æ¼”ç›¸å…³æŒ‡æ ‡
    total_movies = len(director_movies)
    avg_box_office = director_movies['ç¥¨æˆ¿(ä¸‡å…ƒ)'].mean()
    avg_douban_score = director_movies['è±†ç“£è¯„åˆ†'].mean()
    avg_length = director_movies['æ—¶é•¿'].mean()
    avg_avg_people = director_movies['åœºå‡äººæ•°'].mean()  # å‡è®¾ 'åœºå‡äººæ•°' åˆ—å­˜åœ¨

    # è®¡ç®—æ•´ä½“å¹³å‡æŒ‡æ ‡ï¼Œç”¨äºæ ‡å‡†åŒ–
    overall_avg_box_office = processed_df['ç¥¨æˆ¿(ä¸‡å…ƒ)'].mean()
    overall_avg_douban_score = processed_df['è±†ç“£è¯„åˆ†'].mean()
    overall_avg_length = processed_df['æ—¶é•¿'].mean()
    overall_avg_avg_people = processed_df['åœºå‡äººæ•°'].mean()

    all_directors_flat = [d for sublist in processed_df['å¯¼æ¼”_list'] for d in sublist]
    unique_directors_count = len(pd.Series(all_directors_flat).unique())
    # è€ƒè™‘æ•´ä½“å¯¼æ¼”å¹³å‡ç”µå½±æ•°é‡ï¼Œé¿å…é™¤ä»¥é›¶
    overall_total_movies_per_director = len(processed_df) / unique_directors_count if unique_directors_count > 0 else 1

    categories = ['ç”µå½±æ•°é‡', 'å¹³å‡ç¥¨æˆ¿', 'å¹³å‡è¯„åˆ†', 'å¹³å‡ç‰‡é•¿', 'åœºå‡äººæ•°']
    num_vars = len(categories)
    angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]  # è§’åº¦è®¡ç®—
    angles += angles[:1]  # é—­åˆé›·è¾¾å›¾

    # æ ‡å‡†åŒ–æŒ‡æ ‡å€¼ï¼Œé¿å…æŸä¸ªå€¼è¿‡å¤§æˆ–è¿‡å°å¯¼è‡´é›·è¾¾å›¾å¤±è¡¡
    epsilon = 1e-6  # é¿å…é™¤ä»¥é›¶
    values_director = [
        total_movies / (overall_total_movies_per_director + epsilon),
        avg_box_office / (overall_avg_box_office + epsilon),
        avg_douban_score / (overall_avg_douban_score + epsilon),
        avg_length / (overall_avg_length + epsilon),
        avg_avg_people / (overall_avg_avg_people + epsilon)
    ]
    # å°†æ ‡å‡†åŒ–åçš„å€¼é™åˆ¶åœ¨ä¸€ä¸ªåˆç†èŒƒå›´å†…ï¼Œä¾‹å¦‚ä¸è¶…è¿‡2å€å¹³å‡å€¼ï¼Œå¢å¼ºå¯è¯»æ€§
    values_director = [min(v, 2.0) for v in values_director]
    values_director += values_director[:1]

    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))
    ax.fill(angles, values_director, color='red', alpha=0.25)
    ax.plot(angles, values_director, color='red', linewidth=2, linestyle='solid', label=director_name)

    ax.set_yticklabels([])  # ä¸æ˜¾ç¤ºå¾„å‘åˆ»åº¦æ ‡ç­¾
    ax.set_xticks(angles[:-1])  # è®¾ç½®åˆ»åº¦ä½ç½®
    ax.set_xticklabels(categories, color='grey', size=12)  # è®¾ç½®åˆ»åº¦æ ‡ç­¾

    # æ·»åŠ å…·ä½“æ•°å€¼æ ‡ç­¾
    for i, (angle, value) in enumerate(zip(angles[:-1], values_director[:-1])):
        text_val = ""
        if categories[i] == 'ç”µå½±æ•°é‡':
            text_val = f'{total_movies:.0f}éƒ¨'
        elif categories[i] == 'å¹³å‡ç¥¨æˆ¿':
            text_val = f'{avg_box_office / 10000:.1f}äº¿'
        elif categories[i] == 'å¹³å‡è¯„åˆ†':
            text_val = f'{avg_douban_score:.1f}åˆ†'
        elif categories[i] == 'å¹³å‡ç‰‡é•¿':
            text_val = f'{avg_length:.0f}åˆ†é’Ÿ'
        elif categories[i] == 'åœºå‡äººæ•°':
            text_val = f'{avg_avg_people:.1f}äºº'

        # åŠ¨æ€è°ƒæ•´æœ€å¤§åŠå¾„ä»¥å®¹çº³æ ‡ç­¾
        if value * 1.15 > ax.get_rmax():
            ax.set_rmax(value * 1.2)  # å¢åŠ ä¸€äº›è£•é‡

        ax.text(angle, value * 1.15, text_val, color='black', size=10,
                horizontalalignment='center' if angle % (pi / 2) == 0 else ('left' if 0 < angle < pi else 'right'),
                verticalalignment='center' if angle == 0 else ('bottom' if 0 < angle < pi else 'top'))

    ax.set_title(f'å¯¼æ¼” {director_name} å½±å“åŠ›é›·è¾¾å›¾ (ç›¸å¯¹äºå¹³å‡æ°´å¹³)', va='bottom', fontsize=16)
    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))

    st.pyplot(fig)


# --- ç¥¨æˆ¿é¢„æµ‹æ¨¡å‹ ---
@st.cache_data(ttl=3600)
def build_prediction_model(processed_df):
    """æ„å»ºç¥¨æˆ¿é¢„æµ‹æ¨¡å‹ (éšæœºæ£®æ—å’Œçº¿æ€§å›å½’)"""
    st.info("æ­£åœ¨æ„å»ºç¥¨æˆ¿é¢„æµ‹æ¨¡å‹...")

    # é€‰æ‹©ç‰¹å¾åˆ—
    feature_cols = []

    # æ•°å€¼ç‰¹å¾
    numeric_features = ['è±†ç“£è¯„åˆ†', 'è±†ç“£è¯„è®ºæ•°', 'æ—¶é•¿', 'ä¸Šæ˜ å¹´ä»½', 'ä¸Šæ˜ æœˆä»½', 'æ˜¯å¦å‘¨æœ«', 'åœºå‡äººæ•°']
    feature_cols.extend([col for col in numeric_features if col in processed_df.columns])

    # One-Hotç¼–ç ç‰¹å¾ (æ ¹æ®æ•°æ®é¢„å¤„ç†ä¸­ç”Ÿæˆçš„åˆ—ååŠ¨æ€è·å–)
    ohe_cols = [col for col in processed_df.columns if
                any(col.startswith(prefix) for prefix in ['å¯¼æ¼”_', 'ç±»å‹_', 'åœ°åŒº_', 'è¯­è¨€_'])]
    feature_cols.extend(ohe_cols)

    # è¿‡æ»¤æ‰DataFrameä¸­å®é™…ä¸å­˜åœ¨çš„ç‰¹å¾åˆ—ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦å«æœ‰éæ ‡é‡æ•°æ®
    final_feature_cols = []
    for col in feature_cols:
        if col in processed_df.columns:
            # æ£€æŸ¥åˆ—æ˜¯å¦åŒ…å«åˆ—è¡¨ã€å…ƒç»„æˆ–å­—å…¸ç­‰éæ ‡é‡å€¼
            if processed_df[col].apply(lambda x: isinstance(x, (list, tuple, dict))).any():
                st.warning(f"ç‰¹å¾åˆ— '{col}' åŒ…å«éæ ‡é‡å€¼ï¼ˆåˆ—è¡¨/å…ƒç»„/å­—å…¸ï¼‰ã€‚å·²è·³è¿‡è¯¥åˆ—è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚")
            else:
                final_feature_cols.append(col)
        else:
            st.warning(f"ç‰¹å¾åˆ— '{col}' åœ¨å¤„ç†åçš„æ•°æ®ä¸­ä¸å­˜åœ¨ã€‚å·²è·³è¿‡è¯¥åˆ—ã€‚")

    if not final_feature_cols:
        st.error("æ²¡æœ‰å¯ç”¨äºé¢„æµ‹çš„æœ‰æ•ˆç‰¹å¾åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ­¥éª¤ã€‚")
        return None

    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X = processed_df[final_feature_cols].fillna(0)  # å¡«å……å¯èƒ½å­˜åœ¨çš„NaNå€¼
    y = processed_df['ç¥¨æˆ¿(ä¸‡å…ƒ)']

    if X.empty or y.empty:
        st.error("è®­ç»ƒæ•°æ®ä¸ºç©ºï¼Œæ— æ³•æ„å»ºæ¨¡å‹ã€‚è¯·æ£€æŸ¥æ•°æ®æºå’Œè¿‡æ»¤æ¡ä»¶ã€‚")
        return None

    # å†æ¬¡ç¡®è®¤Xä¸­æ²¡æœ‰éæ•°å€¼ç±»å‹ï¼Œç‰¹åˆ«æ˜¯objectç±»å‹
    non_numeric_cols = X.select_dtypes(include=np.number).columns.tolist()
    if len(non_numeric_cols) < len(X.columns):
        st.error(
            f"ç‰¹å¾æ•°æ®Xä¸­åŒ…å«éæ•°å€¼åˆ—ï¼Œè¿™å¯èƒ½å¯¼è‡´StandardScalerå¤±è´¥ã€‚éæ•°å€¼åˆ—: {list(set(X.columns) - set(non_numeric_cols))}")
        st.stop()  # åœæ­¢è¿è¡Œï¼Œè¦æ±‚ç”¨æˆ·æ£€æŸ¥æ•°æ®

    # æ•°æ®åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # ç‰¹å¾æ ‡å‡†åŒ– (å¯¹æ•°å€¼ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # è®­ç»ƒæ¨¡å‹
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
    lr_model = LinearRegression(n_jobs=-1)

    rf_model.fit(X_train_scaled, y_train)
    lr_model.fit(X_train_scaled, y_train)

    # é¢„æµ‹
    rf_pred = rf_model.predict(X_test_scaled)
    lr_pred = lr_model.predict(X_test_scaled)

    # è¯„ä¼°
    rf_r2 = r2_score(y_test, rf_pred)
    lr_r2 = r2_score(y_test, lr_pred)
    rf_mse = mean_squared_error(y_test, rf_pred)
    lr_mse = mean_squared_error(y_test, lr_pred)

    st.success("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    return {
        'rf_model': rf_model,
        'lr_model': lr_model,
        'scaler': scaler,
        'feature_cols': final_feature_cols,  # ä½¿ç”¨å®é™…ç”¨äºè®­ç»ƒçš„ç‰¹å¾åˆ—
        'rf_r2': rf_r2,
        'lr_r2': lr_r2,
        'rf_mse': rf_mse,
        'lr_mse': lr_mse,
        'y_test': y_test,
        'rf_pred': rf_pred,
        'lr_pred': lr_pred
    }


# --- ä¸»åº”ç”¨ç¨‹åºé€»è¾‘ ---
st.title("ç”µå½±ç¥¨æˆ¿é¢„æµ‹ä¸è§‚ä¼—åå¥½åˆ†æ ğŸ¬")
st.markdown("---")

st.sidebar.header("å¯¼èˆª")
page = st.sidebar.radio("é€‰æ‹©é¡µé¢", ["æ•°æ®æ¦‚è§ˆ", "æ¢ç´¢æ€§åˆ†æ", "ç¥¨æˆ¿é¢„æµ‹ä¸å»ºæ¨¡", "å¯¼æ¼”å½±å“åŠ›åˆ†æ"])

# åŠ è½½æ•°æ® (åœ¨æ‰€æœ‰é¡µé¢é€»è¾‘ä¹‹å‰åŠ è½½ä¸€æ¬¡)
processed_df = load_and_preprocess_data(db_connection)

if processed_df.empty:
    st.error("æ•°æ®åŠ è½½æˆ–é¢„å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“å’Œæ•°æ®ã€‚")
    st.stop()  # å¦‚æœæ•°æ®ä¸ºç©ºï¼Œåˆ™åœæ­¢åº”ç”¨ï¼Œé¿å…åç»­æŠ¥é”™

# === é¡µé¢1: æ•°æ®æ¦‚è§ˆ ===
if page == "æ•°æ®æ¦‚è§ˆ":
    st.header("ğŸ“Š æ•°æ®æ¦‚è§ˆ")

    # å…³é”®æŒ‡æ ‡å±•ç¤º
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç”µå½±æ€»æ•°", len(processed_df))
    with col2:
        st.metric("å¹³å‡ç¥¨æˆ¿", f"{processed_df['ç¥¨æˆ¿(ä¸‡å…ƒ)'].mean() / 10000:.2f}äº¿")
    with col3:
        st.metric("å¹³å‡è¯„åˆ†", f"{processed_df['è±†ç“£è¯„åˆ†'].mean():.2f}")
    with col4:
        min_year = processed_df['ä¸Šæ˜ å¹´ä»½'].min() if not processed_df['ä¸Šæ˜ å¹´ä»½'].empty else 'N/A'
        max_year = processed_df['ä¸Šæ˜ å¹´ä»½'].max() if not processed_df['ä¸Šæ˜ å¹´ä»½'].empty else 'N/A'
        st.metric("å¹´ä»½èŒƒå›´", f"{min_year}-{max_year}")

    st.subheader("æ•°æ®è¡¨é¢„è§ˆ")
    # æ˜¾ç¤ºéƒ¨åˆ†æ ¸å¿ƒåˆ—
    display_cols = ['ç”µå½±å', 'ç¥¨æˆ¿(ä¸‡å…ƒ)', 'è±†ç“£è¯„åˆ†', 'ä¸Šæ˜ æ—¥æœŸ', 'æ—¶é•¿', 'åœºå‡äººæ•°', 'å¯¼æ¼”_list', 'ç±»å‹_list']
    available_cols = [col for col in display_cols if col in processed_df.columns]
    st.dataframe(processed_df[available_cols].head(10))

    st.subheader("æ•°æ®åˆ†å¸ƒç»Ÿè®¡")
    numeric_cols = ['ç¥¨æˆ¿(ä¸‡å…ƒ)', 'è±†ç“£è¯„åˆ†', 'è±†ç“£è¯„è®ºæ•°', 'æ—¶é•¿', 'åœºå‡äººæ•°']
    available_numeric = [col for col in numeric_cols if col in processed_df.columns]
    if available_numeric:
        st.dataframe(processed_df[available_numeric].describe().transpose())
    else:
        st.warning("æ— å¯ç”¨çš„æ•°å€¼åˆ—è¿›è¡Œç»Ÿè®¡æè¿°ã€‚")

# === é¡µé¢2: æ¢ç´¢æ€§åˆ†æ ===
elif page == "æ¢ç´¢æ€§åˆ†æ":
    st.header("ğŸ” æ¢ç´¢æ€§æ•°æ®åˆ†æ")

    # ç¥¨æˆ¿åˆ†å¸ƒ
    st.subheader("ç¥¨æˆ¿åˆ†å¸ƒåˆ†æ")
    col1, col2 = st.columns(2)

    with col1:
        if 'ç¥¨æˆ¿(ä¸‡å…ƒ)' in processed_df.columns:
            fig_hist = px.histogram(processed_df, x='ç¥¨æˆ¿(ä¸‡å…ƒ)', nbins=50,
                                    title='ç¥¨æˆ¿åˆ†å¸ƒç›´æ–¹å›¾',
                                    labels={'ç¥¨æˆ¿(ä¸‡å…ƒ)': 'ç¥¨æˆ¿(ä¸‡å…ƒ)', 'count': 'ç”µå½±æ•°é‡'})
            st.plotly_chart(fig_hist, use_container_width=True)
        else:
            st.warning("ç¥¨æˆ¿æ•°æ®ä¸å¯ç”¨ã€‚")

    with col2:
        if 'è±†ç“£è¯„åˆ†' in processed_df.columns and 'ç¥¨æˆ¿(ä¸‡å…ƒ)' in processed_df.columns:
            # ç¥¨æˆ¿vsè¯„åˆ†æ•£ç‚¹å›¾
            # ç”±äºå®‰è£…äº†statsmodelsï¼Œtrendline="ols"ç°åœ¨åº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œ
            fig_scatter = px.scatter(processed_df, x='è±†ç“£è¯„åˆ†', y='ç¥¨æˆ¿(ä¸‡å…ƒ)',
                                     hover_data=['ç”µå½±å'] if 'ç”µå½±å' in processed_df.columns else None,
                                     title='ç¥¨æˆ¿ vs è±†ç“£è¯„åˆ†',
                                     trendline="ols")  # æ·»åŠ OLSè¶‹åŠ¿çº¿
            st.plotly_chart(fig_scatter, use_container_width=True)
        else:
            st.warning("è±†ç“£è¯„åˆ†æˆ–ç¥¨æˆ¿æ•°æ®ä¸å¯ç”¨ã€‚")

    # å¹´åº¦ç¥¨æˆ¿è¶‹åŠ¿
    st.subheader("å¹´åº¦ç”µå½±å¸‚åœºè¶‹åŠ¿")
    if 'ä¸Šæ˜ å¹´ä»½' in processed_df.columns and 'ç¥¨æˆ¿(ä¸‡å…ƒ)' in processed_df.columns and 'è±†ç“£è¯„åˆ†' in processed_df.columns:
        yearly_stats = processed_df.groupby('ä¸Šæ˜ å¹´ä»½').agg(
            æ€»ç¥¨æˆ¿=('ç¥¨æˆ¿(ä¸‡å…ƒ)', 'sum'),
            å¹³å‡ç¥¨æˆ¿=('ç¥¨æˆ¿(ä¸‡å…ƒ)', 'mean'),
            ç”µå½±æ•°é‡=('ç”µå½±å', 'count') if 'ç”µå½±å' in processed_df.columns else ('ç¥¨æˆ¿(ä¸‡å…ƒ)', 'count'),
            å¹³å‡è¯„åˆ†=('è±†ç“£è¯„åˆ†', 'mean')
        ).reset_index()
        # è¿‡æ»¤æ‰ä¸åˆç†çš„å¹´ä»½ï¼ˆå¦‚-1ï¼‰
        yearly_stats = yearly_stats[yearly_stats['ä¸Šæ˜ å¹´ä»½'] > 1900]

        if not yearly_stats.empty:
            fig_yearly = make_subplots(
                rows=2, cols=2,
                subplot_titles=('å¹´åº¦æ€»ç¥¨æˆ¿', 'å¹´åº¦å¹³å‡ç¥¨æˆ¿', 'å¹´åº¦ç”µå½±æ•°é‡', 'å¹´åº¦å¹³å‡è¯„åˆ†'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )

            fig_yearly.add_trace(go.Scatter(x=yearly_stats['ä¸Šæ˜ å¹´ä»½'], y=yearly_stats['æ€»ç¥¨æˆ¿'] / 10000,
                                            name='æ€»ç¥¨æˆ¿(äº¿)', line=dict(color='blue')), row=1, col=1)
            fig_yearly.add_trace(go.Scatter(x=yearly_stats['ä¸Šæ˜ å¹´ä»½'], y=yearly_stats['å¹³å‡ç¥¨æˆ¿'] / 10000,
                                            name='å¹³å‡ç¥¨æˆ¿(äº¿)', line=dict(color='green')), row=1, col=2)
            fig_yearly.add_trace(go.Scatter(x=yearly_stats['ä¸Šæ˜ å¹´ä»½'], y=yearly_stats['ç”µå½±æ•°é‡'],
                                            name='ç”µå½±æ•°é‡', line=dict(color='red')), row=2, col=1)
            fig_yearly.add_trace(go.Scatter(x=yearly_stats['ä¸Šæ˜ å¹´ä»½'], y=yearly_stats['å¹³å‡è¯„åˆ†'],
                                            name='å¹³å‡è¯„åˆ†', line=dict(color='purple')), row=2, col=2)

            fig_yearly.update_layout(height=600, showlegend=False, title_text="å¹´åº¦ç”µå½±å¸‚åœºè¶‹åŠ¿åˆ†æ")
            st.plotly_chart(fig_yearly, use_container_width=True)
        else:
            st.warning("å¹´åº¦è¶‹åŠ¿æ•°æ®ä¸è¶³ä»¥ç»˜åˆ¶å›¾è¡¨ã€‚")
    else:
        st.warning("å¹´åº¦è¶‹åŠ¿åˆ†ææ‰€éœ€æ•°æ®ï¼ˆä¸Šæ˜ å¹´ä»½ã€ç¥¨æˆ¿ã€è¯„åˆ†ï¼‰ä¸å¯ç”¨ã€‚")

    # ç±»å‹åˆ†æ
    st.subheader("ç”µå½±ç±»å‹åˆ†æ")
    if 'ç±»å‹_list' in processed_df.columns and 'ç¥¨æˆ¿(ä¸‡å…ƒ)' in processed_df.columns:
        all_genres = [genre for sublist in processed_df['ç±»å‹_list'] for genre in sublist]
        genre_counts = pd.Series(all_genres).value_counts().head(15)

        col1, col2 = st.columns(2)
        with col1:
            fig_genre_bar = px.bar(x=genre_counts.values, y=genre_counts.index,
                                   orientation='h', title='ç”µå½±ç±»å‹åˆ†å¸ƒ',
                                   labels={'x': 'ç”µå½±æ•°é‡', 'y': 'ç±»å‹'})
            st.plotly_chart(fig_genre_bar, use_container_width=True)

        with col2:
            # ç±»å‹å¹³å‡ç¥¨æˆ¿
            genre_box_office = {}
            for idx, genres in processed_df['ç±»å‹_list'].items():
                box_office = processed_df.loc[idx, 'ç¥¨æˆ¿(ä¸‡å…ƒ)']
                for genre in genres:
                    if genre not in genre_box_office:
                        genre_box_office[genre] = []
                    genre_box_office[genre].append(box_office)

            # è¿‡æ»¤æ‰å‡ºç°æ¬¡æ•°è¿‡å°‘çš„ç±»å‹ï¼Œé¿å…å¼‚å¸¸å€¼å½±å“å¹³å‡æ•°
            MIN_MOVIES_FOR_AVG = 5
            genre_avg_box = {k: np.mean(v) for k, v in genre_box_office.items() if len(v) >= MIN_MOVIES_FOR_AVG}
            genre_avg_box = dict(sorted(genre_avg_box.items(), key=lambda x: x[1], reverse=True)[:10])

            if genre_avg_box:
                fig_genre_avg = px.bar(x=list(genre_avg_box.values()), y=list(genre_avg_box.keys()),
                                       orientation='h', title=f'å„ç±»å‹å¹³å‡ç¥¨æˆ¿Top10 (è‡³å°‘{MIN_MOVIES_FOR_AVG}éƒ¨ç”µå½±)',
                                       labels={'x': 'å¹³å‡ç¥¨æˆ¿(ä¸‡å…ƒ)', 'y': 'ç±»å‹'})
                st.plotly_chart(fig_genre_avg, use_container_width=True)
            else:
                st.info("æ²¡æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—ç±»å‹å¹³å‡ç¥¨æˆ¿ã€‚")
    else:
        st.warning("ç±»å‹æ•°æ®æˆ–ç¥¨æˆ¿æ•°æ®ä¸å¯ç”¨ã€‚")

    # æœˆä»½ä¸Šæ˜ åˆ†æ
    st.subheader("ä¸Šæ˜ æœˆä»½åˆ†æ")
    if 'ä¸Šæ˜ æœˆä»½' in processed_df.columns and 'ç¥¨æˆ¿(ä¸‡å…ƒ)' in processed_df.columns:
        monthly_stats = processed_df.groupby('ä¸Šæ˜ æœˆä»½').agg(
            å¹³å‡ç¥¨æˆ¿=('ç¥¨æˆ¿(ä¸‡å…ƒ)', 'mean'),
            ç”µå½±æ•°é‡=('ç”µå½±å', 'count') if 'ç”µå½±å' in processed_df.columns else ('ç¥¨æˆ¿(ä¸‡å…ƒ)', 'count'),
            å¹³å‡è¯„åˆ†=('è±†ç“£è¯„åˆ†', 'mean')
        ).reset_index()

        col1, col2 = st.columns(2)
        with col1:
            fig_monthly = px.bar(monthly_stats, x='ä¸Šæ˜ æœˆä»½', y='å¹³å‡ç¥¨æˆ¿',
                                 title='å„æœˆä»½å¹³å‡ç¥¨æˆ¿',
                                 labels={'å¹³å‡ç¥¨æˆ¿': 'å¹³å‡ç¥¨æˆ¿(ä¸‡å…ƒ)'})
            st.plotly_chart(fig_monthly, use_container_width=True)

        with col2:
            fig_monthly_count = px.bar(monthly_stats, x='ä¸Šæ˜ æœˆä»½', y='ç”µå½±æ•°é‡',
                                       title='å„æœˆä»½ä¸Šæ˜ ç”µå½±æ•°é‡')
            st.plotly_chart(fig_monthly_count, use_container_width=True)
    else:
        st.warning("ä¸Šæ˜ æœˆä»½æˆ–ç¥¨æˆ¿æ•°æ®ä¸å¯ç”¨ã€‚")

# === é¡µé¢3: ç¥¨æˆ¿é¢„æµ‹ä¸å»ºæ¨¡ ===
elif page == "ç¥¨æˆ¿é¢„æµ‹ä¸å»ºæ¨¡":
    st.header("ğŸ¤– ç¥¨æˆ¿é¢„æµ‹ä¸å»ºæ¨¡")

    # æ„å»ºæ¨¡å‹
    model_results = build_prediction_model(processed_df)

    if model_results:
        # æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        st.subheader("æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        col1, col2 = st.columns(2)

        with col1:
            st.metric("éšæœºæ£®æ— RÂ²", f"{model_results['rf_r2']:.3f}")
            st.metric("éšæœºæ£®æ— MSE", f"{model_results['rf_mse']:.0f}")

        with col2:
            st.metric("çº¿æ€§å›å½’ RÂ²", f"{model_results['lr_r2']:.3f}")
            st.metric("çº¿æ€§å›å½’ MSE", f"{model_results['lr_mse']:.0f}")

        # é¢„æµ‹ç»“æœå¯è§†åŒ–
        st.subheader("é¢„æµ‹ç»“æœå¯¹æ¯”ï¼šå®é™…ç¥¨æˆ¿ vs. é¢„æµ‹ç¥¨æˆ¿")

        # åˆ›å»ºé¢„æµ‹vså®é™…çš„æ•£ç‚¹å›¾
        fig_pred = make_subplots(rows=1, cols=2,
                                 subplot_titles=('éšæœºæ£®æ—é¢„æµ‹', 'çº¿æ€§å›å½’é¢„æµ‹'))

        # éšæœºæ£®æ—
        fig_pred.add_trace(go.Scatter(x=model_results['y_test'],
                                      y=model_results['rf_pred'],
                                      mode='markers',
                                      name='RFé¢„æµ‹',
                                      opacity=0.6), row=1, col=1)

        # æ·»åŠ ç†æƒ³é¢„æµ‹çº¿
        min_val = min(model_results['y_test'].min(), model_results['rf_pred'].min(), model_results['lr_pred'].min())
        max_val = max(model_results['y_test'].max(), model_results['rf_pred'].max(), model_results['lr_pred'].max())
        fig_pred.add_trace(go.Scatter(x=[min_val, max_val],
                                      y=[min_val, max_val],
                                      mode='lines',
                                      name='ç†æƒ³é¢„æµ‹çº¿',
                                      line=dict(dash='dash', color='red')), row=1, col=1)

        # çº¿æ€§å›å½’
        fig_pred.add_trace(go.Scatter(x=model_results['y_test'],
                                      y=model_results['lr_pred'],
                                      mode='markers',
                                      name='LRé¢„æµ‹',
                                      opacity=0.6), row=1, col=2)

        fig_pred.add_trace(go.Scatter(x=[min_val, max_val],
                                      y=[min_val, max_val],
                                      mode='lines',
                                      name='ç†æƒ³é¢„æµ‹çº¿',
                                      line=dict(dash='dash', color='red'),
                                      showlegend=False), row=1, col=2)

        fig_pred.update_xaxes(title_text="å®é™…ç¥¨æˆ¿(ä¸‡å…ƒ)")
        fig_pred.update_yaxes(title_text="é¢„æµ‹ç¥¨æˆ¿(ä¸‡å…ƒ)")
        fig_pred.update_layout(height=500, title_text="é¢„æµ‹ç»“æœå¯¹æ¯”", showlegend=True)  # ç¡®ä¿legendæ˜¾ç¤º
        st.plotly_chart(fig_pred, use_container_width=True)

        # ç‰¹å¾é‡è¦æ€§ï¼ˆéšæœºæ£®æ—ï¼‰
        st.subheader("ç‰¹å¾é‡è¦æ€§åˆ†æ (éšæœºæ£®æ—)")
        feature_importance = pd.DataFrame({
            'feature': model_results['feature_cols'],
            'importance': model_results['rf_model'].feature_importances_
        }).sort_values('importance', ascending=False).head(20)

        fig_importance = px.bar(feature_importance, x='importance', y='feature',
                                orientation='h', title='Top 20 é‡è¦ç‰¹å¾',
                                labels={'importance': 'é‡è¦æ€§', 'feature': 'ç‰¹å¾'})
        st.plotly_chart(fig_importance, use_container_width=True)

        # ç¥¨æˆ¿é¢„æµ‹å·¥å…·
        st.subheader("ğŸ¯ ç¥¨æˆ¿é¢„æµ‹å·¥å…·")
        st.write("è¾“å…¥ç”µå½±å‚æ•°ï¼Œé¢„æµ‹ç¥¨æˆ¿è¡¨ç°ï¼š")

        col1, col2, col3 = st.columns(3)

        with col1:
            douban_score = st.slider("è±†ç“£è¯„åˆ†", 1.0, 10.0, 7.0, 0.1)
            duration = st.slider("ç”µå½±æ—¶é•¿(åˆ†é’Ÿ)", 60, 200, 120)
            release_year = st.slider("ä¸Šæ˜ å¹´ä»½", 2010, pd.Timestamp.now().year + 1, pd.Timestamp.now().year)

        with col2:
            douban_comments = st.number_input("è±†ç“£è¯„è®ºæ•°", 0, 1000000, 10000)
            avg_people = st.slider("åœºå‡äººæ•°", 1, 50, 15)
            release_month = st.selectbox("ä¸Šæ˜ æœˆä»½", list(range(1, 13)), index=5)

        with col3:
            is_weekend = st.selectbox("æ˜¯å¦å‘¨æœ«ä¸Šæ˜ ", [0, 1], index=0, format_func=lambda x: "æ˜¯" if x == 1 else "å¦")

            # è·å–å¤„ç†åçš„ç±»å‹åˆ—è¡¨ï¼Œç¡®ä¿ç”¨æˆ·é€‰æ‹©çš„ç±»å‹åœ¨æ¨¡å‹è®­ç»ƒæ—¶æ˜¯å­˜åœ¨çš„
            all_processed_types = [col.replace('ç±»å‹_', '') for col in model_results['feature_cols'] if
                                   col.startswith('ç±»å‹_')]
            if all_processed_types:
                selected_genre = st.selectbox("ä¸»è¦ç±»å‹", sorted(list(set(all_processed_types))))
            else:
                st.warning("æ¨¡å‹ä¸­æœªæ‰¾åˆ°ç±»å‹ç‰¹å¾ï¼Œè¯·æ£€æŸ¥æ•°æ®é¢„å¤„ç†ã€‚")
                selected_genre = None

        if st.button("é¢„æµ‹ç¥¨æˆ¿") and selected_genre:
            # åˆ›å»ºé¢„æµ‹è¾“å…¥ï¼šä¸€ä¸ªå…¨é›¶çš„Numpyæ•°ç»„ï¼ŒNä¸ºæ¨¡å‹è®­ç»ƒæ—¶ç‰¹å¾åˆ—çš„æ•°é‡
            input_data = {col: 0 for col in model_results['feature_cols']}

            # è®¾ç½®æ•°å€¼ç‰¹å¾
            input_data['è±†ç“£è¯„åˆ†'] = douban_score
            input_data['è±†ç“£è¯„è®ºæ•°'] = douban_comments
            input_data['æ—¶é•¿'] = duration
            input_data['ä¸Šæ˜ å¹´ä»½'] = release_year
            input_data['ä¸Šæ˜ æœˆä»½'] = release_month
            input_data['æ˜¯å¦å‘¨æœ«'] = is_weekend
            input_data['åœºå‡äººæ•°'] = avg_people

            # è®¾ç½®One-Hotç¼–ç çš„ç±»å‹ç‰¹å¾
            genre_col_name = f'ç±»å‹_{selected_genre}'
            if genre_col_name in input_data:
                input_data[genre_col_name] = 1

            # å°†å­—å…¸è½¬æ¢ä¸ºDataFrameçš„ä¸€è¡Œ
            user_input_df = pd.DataFrame([input_data])

            # ç¡®ä¿åˆ—é¡ºåºå’Œæ¨¡å‹è®­ç»ƒæ—¶ä¸€è‡´
            user_input_df = user_input_df[model_results['feature_cols']]

            # æ ‡å‡†åŒ–è¾“å…¥
            pred_input_scaled = model_results['scaler'].transform(user_input_df)

            # è¿›è¡Œé¢„æµ‹
            rf_prediction = model_results['rf_model'].predict(pred_input_scaled)[0]
            lr_prediction = model_results['lr_model'].predict(pred_input_scaled)[0]

            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            col1, col2 = st.columns(2)
            with col1:
                st.success(f"ğŸŒŸ éšæœºæ£®æ—é¢„æµ‹ç¥¨æˆ¿: {rf_prediction / 10000:.2f} äº¿å…ƒ")
            with col2:
                st.info(f"ğŸ“Š çº¿æ€§å›å½’é¢„æµ‹ç¥¨æˆ¿: {lr_prediction / 10000:.2f} äº¿å…ƒ")

            # é¢„æµ‹åŒºé—´
            avg_prediction = (rf_prediction + lr_prediction) / 2
            st.write(f"ğŸ“ˆ ç»¼åˆé¢„æµ‹: **{avg_prediction / 10000:.2f} äº¿å…ƒ**")

            # ç¥¨æˆ¿ç­‰çº§åˆ¤æ–­
            if avg_prediction >= 100000:  # 10äº¿+
                st.balloons()
                st.success("ğŸ‰ é¢„æµ‹ä¸ºè¶…çº§å¤§ç‰‡ï¼ç¥¨æˆ¿æœ‰æœ›è¶…è¿‡10äº¿ï¼")
            elif avg_prediction >= 50000:  # 5äº¿+
                st.success("ğŸ”¥ é¢„æµ‹ä¸ºçƒ­é—¨ç”µå½±ï¼ç¥¨æˆ¿æœ‰æœ›è¾¾åˆ°5-10äº¿ï¼")
            elif avg_prediction >= 10000:  # 1äº¿+
                st.info("ğŸ‘ é¢„æµ‹è¡¨ç°è‰¯å¥½ï¼Œç¥¨æˆ¿æœ‰æœ›è¾¾åˆ°1-5äº¿")
            else:
                st.warning("ğŸ“‰ é¢„æµ‹ç¥¨æˆ¿ç›¸å¯¹è¾ƒä½ï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–è¥é”€ç­–ç•¥")
        elif not selected_genre:
            st.error("è¯·é€‰æ‹©ä¸€ä¸ªä¸»è¦ç±»å‹è¿›è¡Œé¢„æµ‹ã€‚")
    else:
        st.warning("æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œæ— æ³•è¿›è¡Œç¥¨æˆ¿é¢„æµ‹ã€‚")


# === é¡µé¢4: å¯¼æ¼”å½±å“åŠ›åˆ†æ ===
elif page == "å¯¼æ¼”å½±å“åŠ›åˆ†æ":
    st.header("ğŸ¬ å¯¼æ¼”å½±å“åŠ›åˆ†æ")

    if 'å¯¼æ¼”_list' in processed_df.columns and 'ç¥¨æˆ¿(ä¸‡å…ƒ)' in processed_df.columns and 'è±†ç“£è¯„åˆ†' in processed_df.columns:
        all_directors = [d for sublist in processed_df['å¯¼æ¼”_list'] for d in sublist]
        director_stats = {}

        for director in set(all_directors):
            director_movies = processed_df[processed_df['å¯¼æ¼”_list'].apply(lambda x: director in x)]
            if len(director_movies) >= 2:  # è‡³å°‘2éƒ¨ç”µå½±ï¼Œæ•°æ®æ›´æœ‰æ„ä¹‰
                director_stats[director] = {
                    'ç”µå½±æ•°é‡': len(director_movies),
                    'æ€»ç¥¨æˆ¿': director_movies['ç¥¨æˆ¿(ä¸‡å…ƒ)'].sum(),
                    'å¹³å‡ç¥¨æˆ¿': director_movies['ç¥¨æˆ¿(ä¸‡å…ƒ)'].mean(),
                    'å¹³å‡è¯„åˆ†': director_movies['è±†ç“£è¯„åˆ†'].mean(),
                    'å¹³å‡æ—¶é•¿': director_movies['æ—¶é•¿'].mean(),
                    'æ€»è¯„è®ºæ•°': director_movies['è±†ç“£è¯„è®ºæ•°'].sum()
                }

        director_df = pd.DataFrame(director_stats).T.reset_index()
        director_df.columns = ['å¯¼æ¼”', 'ç”µå½±æ•°é‡', 'æ€»ç¥¨æˆ¿', 'å¹³å‡ç¥¨æˆ¿', 'å¹³å‡è¯„åˆ†', 'å¹³å‡æ—¶é•¿', 'æ€»è¯„è®ºæ•°']
        director_df = director_df.sort_values('æ€»ç¥¨æˆ¿', ascending=False)

        if not director_df.empty:
            # é¡¶çº§å¯¼æ¼”æ’è¡Œæ¦œ
            st.subheader("ğŸ“Š å¯¼æ¼”æ’è¡Œæ¦œ")

            tab1, tab2, tab3 = st.tabs(["æ€»ç¥¨æˆ¿æ’è¡Œ", "å¹³å‡ç¥¨æˆ¿æ’è¡Œ", "å¹³å‡è¯„åˆ†æ’è¡Œ"])

            with tab1:
                top_directors_total = director_df.head(15)
                fig_director_total = px.bar(top_directors_total, x='æ€»ç¥¨æˆ¿', y='å¯¼æ¼”',
                                            orientation='h', title='å¯¼æ¼”æ€»ç¥¨æˆ¿Top15',
                                            labels={'æ€»ç¥¨æˆ¿': 'æ€»ç¥¨æˆ¿(ä¸‡å…ƒ)', 'å¯¼æ¼”': 'å¯¼æ¼”'})
                st.plotly_chart(fig_director_total, use_container_width=True)

            with tab2:
                # è¿‡æ»¤å‡ºè‡³å°‘3éƒ¨ç”µå½±çš„å¯¼æ¼”ï¼Œä½¿å¾—å¹³å‡ç¥¨æˆ¿æ›´å…·ä»£è¡¨æ€§
                top_directors_avg = director_df[director_df['ç”µå½±æ•°é‡'] >= 3].sort_values('å¹³å‡ç¥¨æˆ¿',
                                                                                          ascending=False).head(15)
                fig_director_avg = px.bar(top_directors_avg, x='å¹³å‡ç¥¨æˆ¿', y='å¯¼æ¼”',
                                          orientation='h', title='å¯¼æ¼”å¹³å‡ç¥¨æˆ¿Top15 (è‡³å°‘3éƒ¨ç”µå½±)',
                                          labels={'å¹³å‡ç¥¨æˆ¿': 'å¹³å‡ç¥¨æˆ¿(ä¸‡å…ƒ)', 'å¯¼æ¼”': 'å¯¼æ¼”'})
                st.plotly_chart(fig_director_avg, use_container_width=True)

            with tab3:
                top_directors_rating = director_df[director_df['ç”µå½±æ•°é‡'] >= 3].sort_values('å¹³å‡è¯„åˆ†',
                                                                                             ascending=False).head(15)
                fig_director_rating = px.bar(top_directors_rating, x='å¹³å‡è¯„åˆ†', y='å¯¼æ¼”',
                                             orientation='h', title='å¯¼æ¼”å¹³å‡è¯„åˆ†Top15 (è‡³å°‘3éƒ¨ç”µå½±)',
                                             labels={'å¹³å‡è¯„åˆ†': 'å¹³å‡è¯„åˆ†', 'å¯¼æ¼”': 'å¯¼æ¼”'})
                st.plotly_chart(fig_director_rating, use_container_width=True)

            # å¯¼æ¼”è¯¦ç»†åˆ†æ
            st.subheader("ğŸ” å¯¼æ¼”è¯¦ç»†åˆ†æ")

            # å¯¼æ¼”é€‰æ‹©å™¨
            available_directors = sorted(director_df['å¯¼æ¼”'].tolist())
            selected_director = st.selectbox("é€‰æ‹©å¯¼æ¼”è¿›è¡Œè¯¦ç»†åˆ†æ:", available_directors)

            if selected_director:
                director_movies = processed_df[processed_df['å¯¼æ¼”_list'].apply(lambda x: selected_director in x)]

                # å¯¼æ¼”åŸºæœ¬ä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ç”µå½±æ•°é‡", len(director_movies))
                with col2:
                    st.metric("æ€»ç¥¨æˆ¿", f"{director_movies['ç¥¨æˆ¿(ä¸‡å…ƒ)'].sum() / 10000:.1f}äº¿")
                with col3:
                    st.metric("å¹³å‡ç¥¨æˆ¿", f"{director_movies['ç¥¨æˆ¿(ä¸‡å…ƒ)'].mean() / 10000:.2f}äº¿")
                with col4:
                    st.metric("å¹³å‡è¯„åˆ†", f"{director_movies['è±†ç“£è¯„åˆ†'].mean():.1f}")

                # å¯¼æ¼”ç”µå½±åˆ—è¡¨
                st.subheader(f"{selected_director} çš„ç”µå½±ä½œå“")
                movie_cols = ['ç”µå½±å', 'ç¥¨æˆ¿(ä¸‡å…ƒ)', 'è±†ç“£è¯„åˆ†', 'ä¸Šæ˜ æ—¥æœŸ', 'æ—¶é•¿']
                available_movie_cols = [col for col in movie_cols if col in director_movies.columns]

                display_movies = director_movies[available_movie_cols].sort_values('ç¥¨æˆ¿(ä¸‡å…ƒ)', ascending=False)
                st.dataframe(display_movies, use_container_width=True)

                # å¯¼æ¼”ä½œå“è¶‹åŠ¿åˆ†æ
                if len(director_movies) >= 3:  # è‡³å°‘3éƒ¨ç”µå½±æ‰èƒ½çœ‹è¶‹åŠ¿
                    st.subheader(f"{selected_director} ä½œå“è¡¨ç°è¶‹åŠ¿")

                    director_movies_sorted = director_movies.sort_values('ä¸Šæ˜ æ—¥æœŸ')

                    fig_trend = make_subplots(rows=2, cols=1,
                                              subplot_titles=('ç¥¨æˆ¿è¶‹åŠ¿', 'è¯„åˆ†è¶‹åŠ¿'),
                                              vertical_spacing=0.1)

                    fig_trend.add_trace(go.Scatter(x=director_movies_sorted['ä¸Šæ˜ æ—¥æœŸ'],
                                                   y=director_movies_sorted['ç¥¨æˆ¿(ä¸‡å…ƒ)'] / 10000,
                                                   mode='lines+markers',
                                                   name='ç¥¨æˆ¿(äº¿)'), row=1, col=1)

                    fig_trend.add_trace(go.Scatter(x=director_movies_sorted['ä¸Šæ˜ æ—¥æœŸ'],
                                                   y=director_movies_sorted['è±†ç“£è¯„åˆ†'],
                                                   mode='lines+markers',
                                                   name='è±†ç“£è¯„åˆ†',
                                                   line=dict(color='orange')), row=2, col=1)

                    fig_trend.update_layout(height=500, title_text=f"{selected_director} ä½œå“è¡¨ç°è¶‹åŠ¿",
                                            showlegend=False)
                    st.plotly_chart(fig_trend, use_container_width=True)
                else:
                    st.info(f"å¯¼æ¼” {selected_director} ä½œå“æ•°é‡ä¸è¶³ï¼Œæ— æ³•ç»˜åˆ¶è¶‹åŠ¿å›¾ã€‚")

                # é›·è¾¾å›¾åˆ†æ
                st.subheader(f"{selected_director} å½±å“åŠ›é›·è¾¾å›¾")
                plot_director_radar_chart(selected_director, processed_df)

            # å¯¼æ¼”å¯¹æ¯”åˆ†æ
            st.subheader("ğŸ†š å¯¼æ¼”å¯¹æ¯”åˆ†æ")

            col1, col2 = st.columns(2)
            with col1:
                director1 = st.selectbox("é€‰æ‹©å¯¼æ¼”1:", available_directors, key="director1")
            with col2:
                director2 = st.selectbox("é€‰æ‹©å¯¼æ¼”2:", available_directors, key="director2",
                                         index=1 if len(available_directors) > 1 else 0)

            if director1 and director2 and director1 != director2:
                director1_movies = processed_df[processed_df['å¯¼æ¼”_list'].apply(lambda x: director1 in x)]
                director2_movies = processed_df[processed_df['å¯¼æ¼”_list'].apply(lambda x: director2 in x)]

                comparison_df = pd.DataFrame({
                    'æŒ‡æ ‡': ['ç”µå½±æ•°é‡', 'æ€»ç¥¨æˆ¿(äº¿)', 'å¹³å‡ç¥¨æˆ¿(äº¿)', 'å¹³å‡è¯„åˆ†', 'å¹³å‡æ—¶é•¿(åˆ†é’Ÿ)'],
                    director1: [
                        len(director1_movies),
                        director1_movies['ç¥¨æˆ¿(ä¸‡å…ƒ)'].sum() / 10000,
                        director1_movies['ç¥¨æˆ¿(ä¸‡å…ƒ)'].mean() / 10000,
                        director1_movies['è±†ç“£è¯„åˆ†'].mean(),
                        director1_movies['æ—¶é•¿'].mean()
                    ],
                    director2: [
                        len(director2_movies),
                        director2_movies['ç¥¨æˆ¿(ä¸‡å…ƒ)'].sum() / 10000,
                        director2_movies['ç¥¨æˆ¿(ä¸‡å…ƒ)'].mean() / 10000,
                        director2_movies['è±†ç“£è¯„åˆ†'].mean(),
                        director2_movies['æ—¶é•¿'].mean()
                    ]
                })

                st.dataframe(comparison_df.round(2), use_container_width=True)
            elif director1 == director2 and director1:
                st.warning("è¯·é€‰æ‹©ä¸¤ä½ä¸åŒçš„å¯¼æ¼”è¿›è¡Œå¯¹æ¯”ã€‚")
            else:
                st.info("è¯·é€‰æ‹©ä¸¤ä½å¯¼æ¼”è¿›è¡Œå¯¹æ¯”ã€‚")

        else:
            st.warning("æ²¡æœ‰è¶³å¤Ÿçš„å¯¼æ¼”æ•°æ®è¿›è¡Œåˆ†æã€‚")
    else:
        st.error("å¯¼æ¼”ç›¸å…³æ•°æ®ï¼ˆå¯¼æ¼”åˆ—è¡¨ã€ç¥¨æˆ¿ã€è¯„åˆ†ï¼‰ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æ•°æ®é¢„å¤„ç†ã€‚")

# ä¾§è¾¹æ é¢å¤–ä¿¡æ¯
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“ˆ æ•°æ®æ´å¯Ÿ")

if not processed_df.empty:
    # æ˜¾ç¤ºä¸€äº›æœ‰è¶£çš„ç»Ÿè®¡
    # ä½¿ç”¨ .get() å®‰å…¨åœ°è®¿é—®åˆ—ï¼Œå¹¶æä¾›é»˜è®¤å€¼
    highest_grossing_col = 'ç¥¨æˆ¿(ä¸‡å…ƒ)'
    highest_rated_col = 'è±†ç“£è¯„åˆ†'
    movie_name_col = 'ç”µå½±å'

    if highest_grossing_col in processed_df.columns and not processed_df[highest_grossing_col].empty:
        highest_grossing = processed_df.loc[processed_df[highest_grossing_col].idxmax()]
        st.sidebar.markdown(f"**æœ€é«˜ç¥¨æˆ¿ç”µå½±:**")
        if movie_name_col in processed_df.columns:
            st.sidebar.write(f"ğŸ¬ {highest_grossing.get(movie_name_col, 'N/A')}")
        st.sidebar.write(f"ğŸ’° {highest_grossing[highest_grossing_col] / 10000:.1f}äº¿")
    else:
        st.sidebar.info("æœ€é«˜ç¥¨æˆ¿ç”µå½±æ•°æ®ä¸å¯ç”¨ã€‚")

    if highest_rated_col in processed_df.columns and not processed_df[highest_rated_col].empty:
        highest_rated = processed_df.loc[processed_df[highest_rated_col].idxmax()]
        st.sidebar.markdown(f"**æœ€é«˜è¯„åˆ†ç”µå½±:**")
        if movie_name_col in processed_df.columns:
            st.sidebar.write(f"ğŸ¬ {highest_rated.get(movie_name_col, 'N/A')}")
        st.sidebar.write(f"â­ {highest_rated[highest_rated_col]:.1f}åˆ†")
    else:
        st.sidebar.info("æœ€é«˜è¯„åˆ†ç”µå½±æ•°æ®ä¸å¯ç”¨ã€‚")

    # æ˜¾ç¤ºæ•°æ®æ›´æ–°æ—¶é—´
    st.sidebar.markdown("---")
    st.sidebar.markdown("**æ•°æ®è¯´æ˜:**")
    st.sidebar.write("â€¢ æ•°æ®æ¥æº: çŒ«çœ¼ç”µå½± (å‡è®¾)")
    st.sidebar.write("â€¢ åŒ…å«ç¥¨æˆ¿ã€è¯„åˆ†ã€å¯¼æ¼”ã€ç±»å‹ç­‰ä¿¡æ¯")
    st.sidebar.write("â€¢ æ”¯æŒåŸºäºå†å²æ•°æ®è¿›è¡Œç¥¨æˆ¿é¢„æµ‹")
else:
    st.sidebar.warning("æš‚æ— æ•°æ®å¯ä¾›åˆ†æã€‚")

# é¡µè„š
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>ğŸ¬ ç”µå½±ç¥¨æˆ¿åˆ†æç³»ç»Ÿ | åŸºäºæœºå™¨å­¦ä¹ çš„ç¥¨æˆ¿é¢„æµ‹ ğŸ“Š</p>
        <p><small>æ•°æ®é©±åŠ¨å†³ç­–ï¼ŒåŠ©åŠ›ç”µå½±äº§ä¸šå‘å±•</small></p>
    </div>
    """,
    unsafe_allow_html=True
)